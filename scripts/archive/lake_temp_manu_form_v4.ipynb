{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lake_temp_manu_form_v4.ipynb","private_outputs":true,"provenance":[{"file_id":"1AJFnCB7B7Uev2-0hqIayOb5fkSB0Xn8v","timestamp":1623171309871},{"file_id":"1U_O3YgDRCNrZCAWCdL0X1Z422cu4Oo6I","timestamp":1620745209104}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tr9ipVEDv7BK"},"source":["*Version 4*<br>\n","*Last updated: 2021-06-08<p>*\n","christina.herrick@unh.edu<br>\n","steeleb@caryinstitute.org<br>\n","__Please do not distribute__"]},{"cell_type":"markdown","metadata":{"id":"_3j2wXvAmLcR"},"source":["## Chris to-do:\n","Add flag to export csv:\n","\n","\n","*   too cold pixels\n","*   -1 > skew > 1\n","* set up export of all available site-specific data where available? (low priority)\n","\n","## B changes\n","\n","* user-defined drive path to remaining export of .csv's and ancillary data\n"]},{"cell_type":"markdown","metadata":{"id":"psnrRlTjBj2M"},"source":["# Initial Setup\n","\n","This notebook uses the [Google Earth Engine](https://developers.google.com/earth-engine) [Python API](https://developers.google.com/earth-engine/guides/python_install) to apply the Single-Channel (SC) algorithm, a model-based algorithm using atmospheric correction coefficients, to Landsat thermal imagery and derives water body skin surface temperatures. \n","\n","Algorithms for Landsat 4,5,7 can be found in *Jiménez-Muñoz, J. C., J. Cristóbal, J. A. Sobrino, G. Soria, N. Ninyerola, and X. Pons. 2009. Revision of the Single-Channel Algorithm for Land Surface Temperature Retrieval From Landsat Thermal-Infrared Data. IEEE Transactions on Geoscience and Remote Sensing 47:339–349.* [https://doi.org/10.1109/TGRS.2008.2007125](https://doi.org/10.1109/TGRS.2008.2007125)\n","\n","Algorithms for Landsat 8 can be found in *Jiménez-Muñoz, J. C., J. A. Sobrino, D. Skoković, C. Mattar, and J. Cristóbal. 2014. Land Surface Temperature Retrieval Methods From Landsat-8 Thermal Infrared Sensor Data. IEEE Geoscience and Remote Sensing Letters 11:1840–1843.* [https://doi.org/10.1109/LGRS.2014.2312032](https://doi.org/10.1109/LGRS.2014.2312032)\n"]},{"cell_type":"markdown","metadata":{"id":"y2hwVo9OVsL-"},"source":["To run this script successfully, the bounding box coordinates of a lake are entered in a Google Spreadsheet. If you need help finding those coordinates, try using [OpenStreetMap](https://www.openstreetmap.org/export#map=12/43.3826/-72.0157). The bounding box should be as small as possible while still including the entire lake surface."]},{"cell_type":"markdown","metadata":{"id":"g3zRra91DaEq"},"source":["## Modules\n","\n","This section of code blocks imports necessary python modules for the notebook to run. You will be prompted to click one or more URLs and be taken to a page to sign in with your Google account. This account must already be authorized to use Google Earth Engine. If you do not already have access, [fill out this application](https://signup.earthengine.google.com/#!/).\n","\n","Copy the unique code(s) provided on the web page when prompted and paste where prompted to finish authorization."]},{"cell_type":"code","metadata":{"id":"gh-VYdMKCAkM","cellView":"form"},"source":["#@markdown __Run this block__ to authorize Colab to authenticate your Google account and give it access to upload files from your local computer ([to be used later](https://colab.research.google.com/drive/1AJFnCB7B7Uev2-0hqIayOb5fkSB0Xn8v#scrollTo=L_Tf54wwIPRy) in the notebook)\n","from google.colab import auth, files\n","auth.authenticate_user()\n","import gspread\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STd1_lFcVYMZ","cellView":"form"},"source":["#@markdown __Run this block__ to connect Colab to your Earth Engine account\n","import ee\n","ee.Authenticate()\n","ee.Initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaB_g_reJG41","cellView":"form"},"source":["#@markdown __Run this block__ to connect Colab to your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SN2nSfHBF1S","cellView":"form"},"source":["#@markdown __Run this block__ to install packages and functions used for \n","#@markdown interactive mapping and data exploration (double-click to reveal code)\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","import matplotlib.pyplot as plt\n","from time import strftime, sleep\n","from datetime import datetime, timedelta\n","import pytz\n","import folium\n","from folium import plugins\n","from google.colab import data_table\n","\n","# Add custom basemaps to folium\n","basemaps = {\n","    'Google Maps': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Maps',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Google Satellite': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Satellite',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Google Terrain': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Terrain',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Google Satellite Hybrid': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Satellite',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Esri Satellite': folium.TileLayer(\n","        tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n","        attr = 'Esri',\n","        name = 'Esri Satellite',\n","        overlay = True,\n","        control = True\n","    )\n","}\n","\n","# Define a method for displaying Earth Engine image tiles on a folium map.\n","def add_ee_layer(self, ee_object, vis_params, name):\n","    \n","    try:    \n","        # display ee.Image()\n","        if isinstance(ee_object, ee.image.Image):    \n","            map_id_dict = ee.Image(ee_object).getMapId(vis_params)\n","            folium.raster_layers.TileLayer(\n","            tiles = map_id_dict['tile_fetcher'].url_format,\n","            attr = 'Google Earth Engine',\n","            name = name,\n","            overlay = True,\n","            control = True\n","            ).add_to(self)\n","        # display ee.ImageCollection()\n","        elif isinstance(ee_object, ee.imagecollection.ImageCollection):    \n","            ee_object_new = ee_object.mosaic()\n","            map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n","            folium.raster_layers.TileLayer(\n","            tiles = map_id_dict['tile_fetcher'].url_format,\n","            attr = 'Google Earth Engine',\n","            name = name,\n","            overlay = True,\n","            control = True\n","            ).add_to(self)\n","        # display ee.Geometry()\n","        elif isinstance(ee_object, ee.geometry.Geometry):    \n","            folium.GeoJson(\n","            data = ee_object.getInfo(),\n","            name = name,\n","            overlay = True,\n","            control = True\n","        ).add_to(self)\n","        # display ee.FeatureCollection()\n","        elif isinstance(ee_object, ee.featurecollection.FeatureCollection):  \n","            ee_object_new = ee.Image().paint(ee_object, 0, 2)\n","            map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n","            folium.raster_layers.TileLayer(\n","            tiles = map_id_dict['tile_fetcher'].url_format,\n","            attr = 'Google Earth Engine',\n","            name = name,\n","            overlay = True,\n","            control = True\n","        ).add_to(self)\n","    \n","    except:\n","        print(\"Could not display {}\".format(name))\n","    \n","# Add EE drawing method to folium.\n","folium.Map.add_ee_layer = add_ee_layer\n","\n","print(\"Packages installed\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1C4zmuTIA8SR"},"source":["## Imported variables\n","These are Landsat-specific variable settings for GEE."]},{"cell_type":"code","metadata":{"id":"CkiZcezXBEG5","cellView":"form"},"source":["#@markdown __Run this block__ to import pre-existing features, images, and collections from Earth Engine (double-click to reveal code)\n","wrs2 = ee.FeatureCollection(\"users/christinaherrickunh/WRS2_descending_2018\")\n","utmbounds = ee.FeatureCollection(\"users/christinaherrickunh/UTM_Zone_Boundaries\")\n","sw = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\")\n","ag100 = ee.Image(\"NASA/ASTER_GED/AG100_003\")\n","vapor = ee.ImageCollection(\"NCEP_RE/surface_wv\")\n","l4t1 = ee.ImageCollection(\"LANDSAT/LT04/C01/T1\")\n","l4t2 = ee.ImageCollection(\"LANDSAT/LT04/C01/T2\")\n","l5t1 = ee.ImageCollection(\"LANDSAT/LT05/C01/T1\")\n","l5t2 = ee.ImageCollection(\"LANDSAT/LT05/C01/T2\")\n","l7t1 = ee.ImageCollection(\"LANDSAT/LE07/C01/T1\")\n","l7t2 = ee.ImageCollection(\"LANDSAT/LE07/C01/T2\")\n","l8t1 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1\")\n","l8t2 = ee.ImageCollection(\"LANDSAT/LC08/C01/T2\")\n","\n","print(\"variables installed\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkoErj-_1wN1"},"source":["Atmospheric functions are derived from modeling the [TIGR2311](https://doi.org/10.1175/1520-0450(2002)041%3C0144:ARNNAF%3E2.0.CO;2) atmospheric sounding database, except Landsat 8, which come from [GAPRI4838](http://dx.doi.org/10.1080/01431161.2015.1054965). These are necessary for the Single-Channel algorithm to run successfully. "]},{"cell_type":"code","metadata":{"id":"SxNwes53kc4U","cellView":"form"},"source":["#@markdown __Run this block__ to import atmospheric functions\n","coeff4 = [0.06674,-0.03447,1.04483,-0.50095,-1.15652,0.09812,-0.04732,1.50453,-0.34405] #  TIGR2311\n","coeff5 = [0.08158,-0.05707,1.05991,-0.58853,-1.08536,-0.00448,-0.06201,1.59086,-0.33513] #  TIGR2311\n","coeff7 = [0.06982,-0.03366,1.04896,-0.51041,-1.20026,0.10490,-0.05457,1.52631,-0.32136] #  TIGR2311\n","coeff8 = [0.04019,0.02916,1.01523,-0.38333,-1.50294,0.20324,0.00918,1.36072,-0.27514] #  GAPRI4838\n","print(\"Coefficients imported\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4d-W11qiD-U"},"source":["\n","Landsat scenes contain a QA band meant for bitwise masking of pixels. Information can be found at [USGS](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collection-1-level-1-quality-assessment-band?qt-science_support_page_related_con=0#qt-science_support_page_related_con). \n","\n","Below are lists of binary pixel values used for quality control, represented as `qa_values` (Landsat 4,5,7) and as `qa_val_8` (Landsat 8). <br>\n","Cloud, snow, and ice pixels are removed.\n","\n","Excel spreadsheets of pixel quality values and their definititions can be found:\n","- for Landat 4-7 [here](https://unh.box.com/v/landsat4-7-qavalues); \n","- for Landsat 8, [here](https://unh.box.com/v/landsat8-qavalues)"]},{"cell_type":"code","metadata":{"id":"to3lDRUviGuD","cellView":"form"},"source":["#@markdown __Run this block__ to set masked pixels from the Landsat QA bands\n","qa_values = ee.List([672,676,680,684,704,708,712,716,928,932,936,940,960,964,968,972]) #  KEEP these pixel values\n","                        # 1696,1700,1704,1708,1728,1732,1736,1740]) <-- these are snow/ice\n","\n","qa_val_8 = ee.List([2,2720,2722,2724,2728,2732,2752,2756,2760,2764,2976,2980,2984,2988,3008,3012,3016,3020]) #  KEEP these pixel values\n","                        # ,3744,3748,3752,3756,3776,3780,3784,3788]); <-- these are snow/ice"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxgpEciUBKLy"},"source":["## User-set variables\n","\n","In this section, use either *Option A*, where you define the bounding box, or *Option B* where you import a shape file of your lake. \n","\n","The final section, *Set Remaining Variables*, defines acceptable lake coverage percent, RMSE of Landsat Tier 2 inclusion, dates of interest, and path/row of Landsat flyover."]},{"cell_type":"markdown","metadata":{"id":"9JiuNetjpgpJ"},"source":["###Option A: use a bounding box\n","If you need help finding your coordinates, try using [OpenStreetMap](https://www.openstreetmap.org/export#map=12/43.3826/-72.0157). The bounding box should be as small as possible while still including the entire lake surface.<p>\n","Enter coordinates to see a map of the bounding box. You can also click on the map to get interactive pop-ups of the latitude (y) and longitude (x), and replace/re-run the coordinates."]},{"cell_type":"code","metadata":{"id":"eQX8qmNz_aLM","cellView":"form"},"source":["#@markdown __Run this block__ after inputting your coordinates below.\n","#@markdown Do not run this block if you are using Option B\n","\n","#@markdown `lat1` = North\n","lat1 = '43.4342'  #@param {type:\"string\"}\n","#@markdown `lat2` = South\n","lat2 = '43.3162'  #@param {type:\"string\"}\n","#@markdown `lon1` = West\n","lon1 = '-72.0937'  #@param {type:\"string\"}\n","#@markdown `lon2` = East\n","lon2 = '-72.0133'  #@param {type:\"string\"}\n","\n","use_user_input_file = \"no\"\n","try:\n","  lat1 = float(lat1)\n","  lon1 = float(lon1)\n","  lat2 = float(lat2)\n","  lon2 = float(lon2)\n","except ValueError as e:\n","  raise ValueError(\"Coordinates are missing or are not numbers\")\n","box = ee.Geometry.Polygon(\n","    [[[lon1, lat1], # ur\n","      [lon2, lat1], # ul\n","      [lon2, lat2], # ll\n","      [lon1, lat2]]], None, False) # lr\n","center_lat = (lat1+lat2)/2\n","center_lon = (lon1+lon2)/2\n","locs_map = folium.Map(location=[center_lat,center_lon],zoom_start=10,width=600,height=600)\n","locs_map.add_child(folium.LatLngPopup())\n","basemaps['Google Maps'].add_to(locs_map)\n","locs_map.add_ee_layer(box,{},'aoi')\n","display(locs_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBZzaGgqpr8W"},"source":["###Option B: upload a table file\n","Using your Google Earth Engine account, upload a shapefile or csv of your study lake to your Assets and link to it here.<p>Click [here](https://drive.google.com/file/d/1lfFoZzQD_wAA7Bnil7mI4zwjKDG5kegh/view?usp=sharing) and [here](https://drive.google.com/file/d/1KNaZV63J_LUp6X1OcoLX1wonF0ASiIzi/view?usp=sharing) for screenshots of the process. "]},{"cell_type":"code","metadata":{"id":"e0lONKBvqAUp","cellView":"form"},"source":["#@markdown File path should begin with 'users/'\n","user_input_file = \"users/steeleb/sunapee\" #@param {type: \"string\"}\n","use_user_input_file = \"yes\" #@param [\"yes\",\"no\"] {allow-input: true}\n","#@markdown Remember to __run this block__ after filling in the above fields.\n","#@markdown Do not run this block if you are using Option A."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIKkHHMnKqik"},"source":["#@markdown For Opt B, __run this block__ to calculate the centroid latitude and longitude\n","if len(user_input_file)>1:\n","  shp = ee.FeatureCollection(user_input_file).geometry()\n","  centroid = shp.centroid(10).getInfo()[\"coordinates\"]\n","  center_lat = centroid[1]\n","  center_lon = centroid[0]\n","  print(center_lat)\n","  print(center_lon)\n","else:\n","  print(\"No file input; will use Opt A bounding box coordinates\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"93P5zojCKmwm"},"source":["#@markdown For Opt B, __run this block__ to confirm the waterbody AOI\n","if 'shp' in globals() or 'shp' in locals():\n","  shp_map = folium.Map(location=[center_lat,center_lon],zoom_start=10,width=600,height=600)\n","  shp_map.add_child(folium.LatLngPopup())\n","  basemaps['Google Maps'].add_to(shp_map)\n","  shp_map.add_ee_layer(shp,{},'aoi')\n","  display(shp_map)\n","else:\n","  print(\"Display does not apply here; Opt A bounding box is being used for AOI\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDrkGq_jwgIo"},"source":["### Set remaining variables\n","This section defines acceptable water persistence and error for the Landsat pixels, the time period of interest, and confirms the path and row for Landsat acquisition. You can also change the default Google Drive folder for any outputs."]},{"cell_type":"code","metadata":{"cellView":"form","id":"L5s5K2jQm9Zt"},"source":["#@markdown The default path for any exports is in the Colab Notebooks directory \n","#@markdown within Google Drive. If preferred, it can be changed here\n","output_dir = \"/content/drive/MyDrive/herrick_etal_temp\" #@param {type:\"string\"}\n","#@markdown Enter a file naming prefix for any exports (no spaces or special characters)\n","file_prefix = \"sunapee\" #@param {type:\"string\"}\n","\n","if not os.path.exists(output_dir):\n","  os.makedirs(output_dir)\n","\n","def check_splcharacter(test):\n","  string_check = re.compile('[@!#$%^&*() <>?/\\|}{~:]')\n","  if not string_check.search(test)==None:\n","    print(\"Your file prefix contains special characters, please fix\")\n","    file_prefix = \"your_lake_name\"\n","  else:\n","    print(\"File prefix:\",test)\n","\n","check_splcharacter(file_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwhZWCrkVrb0","cellView":"form"},"source":["#@markdown Boundaries of water bodies are automatically detected using the JRC \n","#@markdown Global Surface Water Mapping Layer dataset of percent water occurrence. \n","#@markdown By default, a pixel has to be classified as water at least 55% of the \n","#@markdown time. This is defined as `pctTime`\n","\n","#@markdown <p>More information on this dataset can be found at https://doi.org/10.1038/nature20584\n","\n","pctTime = 55  #@param {type: \"number\"}\n","#@markdown __Run this block__ after inputting the above parameter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"N9WlKk7iHcRC"},"source":["#@markdown Landsat scenes from both Tier 1 and Tier 2 of Collection 1 are \n","#@markdown included for possible use. From Tier 2, only scenes that are processed \n","#@markdown to L1T with a combined RMS error of no greater than 30 meters are \n","#@markdown considered.\n","rmse = 30  #@param {type: \"number\"}\n","#@markdown __Run this block__ after inputting the above parameter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypJaiep9n1F7","cellView":"form"},"source":["#@markdown Landsat records begin in 1984 with Landsat 4 TM. \n","#@markdown Enter the year range that you want to search, as well as months of \n","#@markdown the year. To search all months, `m1 = 1` and `m2 = 12` <p>\n","#@markdown <p>First year (y1) and last year (y2). Years are inclusive.<p>\n","#@markdown <p>First month (m1) and last month (m2). Months are inclusive.<p>\n","#@markdown <p>Note that this method has only been developed for lake ice-off temperature estimation. \n","\n","y1 = 1985 #@param {type: \"number\"}\n","y2 = 2020 #@param {type: \"number\"}\n","\n","m1 = 5 #@param {type: \"number\"}\n","m2 =  11#@param {type: \"number\"}\n","print('Script will search years %d through %d and months %d through %d of each year' % (y1,y2,m1,m2))\n","#@markdown __Run this block__ after inputting the above parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stjrJlU2HamN","cellView":"form"},"source":["#@markdown __Run this block__ to calculate the Landsat path(s) and row(s) that \n","#@markdown overlap the extent of Option A/B It will print as\n","#@markdown `WRS2 Path/Row: PPPRRR` where `PPP` is the three-digit path, and \n","#@markdown `RRR` is the three-digit row.\n","\n","if use_user_input_file==\"yes\":\n","  try:\n","    box = shp\n","  except NameError:\n","    raise NameError(\"Cannot find user-input file. Are you using Option B or Opt A bounding box? You may need to correct and rerun.\")\n","\n","pathrow = wrs2.filterBounds(box)\n","  \n","num_of_pr = len(pathrow.getInfo()[\"features\"])\n","path_west = 1\n","path_east = 233\n","row_north = 122\n","row_south = 1\n","\n","print('landsat path/rows:')\n","for i in range(0,num_of_pr):\n","  pr = pathrow.getInfo()[\"features\"][i][\"properties\"][\"PR\"]\n","  p = pr[:3]\n","  r = pr[3:]\n","  if int(p) > path_west:\n","    path_west = int(p)\n","  if int(p) < path_east:\n","    path_east = int(p)\n","  if int(r) < row_north:\n","    row_north = int(r)\n","  if int(r) > row_south:\n","    row_south = int(r)\n","  print(f\"p{p} r{r}\")\n","\n","utm = utmbounds.filterBounds(box)\n","printUTM = utm.getInfo()[\"features\"][0][\"properties\"][\"ZONE\"]\n","print(\"UTM Zone:\",printUTM, \"(does not print more than one zone if more are present)\")\n","crs_out = f\"EPSG:326{printUTM}\"\n","\n","zone_map = folium.Map(location=[center_lat,center_lon],zoom_start=7,width=600,height=600)\n","zone_map.add_child(folium.LatLngPopup())\n","basemaps['Google Maps'].add_to(zone_map)\n","zone_map.add_ee_layer(utm,{},'utm zone(s)')\n","zone_map.add_ee_layer(pathrow,{},'path row')\n","zone_map.add_ee_layer(box,{},'aoi box')\n","display(zone_map)\n","print(f'\\nbounding paths: {path_west} to {path_east}')\n","print(f'bounding rows: {row_north} to {row_south}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XdAVBs0vRT17","cellView":"form"},"source":["#@markdown Use the printed statement above to guide your entry for the path and row variables below. If there is only one path and/or one row, enter the same number for `p1,p2` and `r1,r2` <p> \n","#@markdown Starting and ending path (*Path 233 starts at the Prime Meridian and decreases moving west-east*)\n","p1 = 13 #@param {type: \"number\"}\n","p2 =  13#@param {type: \"number\"}\n","#@markdown Starting row (*Row 1 starts in the Arctic and increases moving north-south*)\n","r1 =  30#@param {type: \"number\"}\n","r2 = 30 #@param {type: \"number\"}\n","print(f\"path {p1} to {p2}, row {r1} to {r2}\")\n","#@markdown __Run this block__ after inputting the above parameters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xE7MPgvY78u"},"source":["# Find water pixels & delineate boundary\n","This step uses the bounding box or the table file as well as the water persistence using [JRC Water dataset](https://global-surface-water.appspot.com/) to define the waterbody area. \n","\n","Note, in some cases the _Opt A_ bounding box method will include upstream and downstream water areas, particularily where there are rivers that are large enough to be detected by Landsat. To avoid this, use the _Opt B_ table file method. <p>\n","You can explore the JRC Water dataset [here](https://global-surface-water.appspot.com/).<p>"]},{"cell_type":"code","metadata":{"id":"V1ljgJffQF1Y","cellView":"form"},"source":["#@markdown This code block reduces the bounding box defined above to the largest water body present, and then counts the 30m pixels within the water body.<p>\n","#@markdown Landsat scenes included in analysis must have a minimum percentage of clear lake pixels available (these are discontinuous pixels)\n","pctLakeCoverage = 25 #@param\n","#@markdown __Run this block__ after inputting the above parameter\n","\n","wateroccurrence = sw.select(0)\n","water = wateroccurrence.gte(pctTime)\n","water = water.updateMask(water.neq(0))\n","\n","def addArea(feature):\n","  # returns area +/- 1sqm\n","  return feature.set({'area':feature.geometry().area(1)})  \n","\n","regions = water.addBands(wateroccurrence).reduceToVectors(\n","    reducer=ee.Reducer.min(),\n","    geometry=box,\n","    scale=30,\n","    maxPixels=5e9,\n","    geometryInNativeProjection=True,\n","    labelProperty='surfaceWater').map(addArea).sort('area',False);\n","\n","lake_outline = ee.Feature(regions.first())\n","aoi = lake_outline\n","geo = lake_outline.geometry()\n","coords = geo.getInfo()['coordinates'][0]\n","\n","watercount = water.reduceRegion(reducer=ee.Reducer.count().unweighted(), \n","                                geometry=lake_outline.geometry(),\n","                                scale=30, bestEffort=True)\n","totalpixels = watercount.getInfo()[\"occurrence\"]\n","pixel_min = totalpixels*(pctLakeCoverage/100.0)\n","print(\"\\n\\nTotal # of lake pixels: \", totalpixels);\n","print(f\"{pctLakeCoverage}% of available lake pixels is\", int(pixel_min))\n","\n","pixel_map = folium.Map(location=[center_lat,center_lon],zoom_start=10, width=600, height=600)\n","basemaps['Google Satellite'].add_to(pixel_map)\n","pixel_map.add_ee_layer(geo ,{},'pixels over lake')\n","display(pixel_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45tElCUuotvD"},"source":["# Calculate Skin Surface Temperatures\n","Using all of the information amassed so far, the code blocks in this section perform all necessary steps to get skin temperature."]},{"cell_type":"code","metadata":{"id":"Cbd6m5SRlsyF","cellView":"form"},"source":["#@title Landsat functions\n","#@markdown __Run this block__ to define the functions that pre-process and \n","#@markdown atmospherically correct Landsat images to water skin temperature.\n","def prep4bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B6'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[1-6]'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff4).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1290).select([0],['Bg'])\n","\n","  #  use the QA band to mask pixels  \n","  p_qa = img.select([\"BQA\"])\n","  p_mask = p_qa.remap(qa_values,qa_values).mask().int8()\n","  \n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime)\n","  \n","  return ee.Image(both)\n","\n","def prep5bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B6'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[1-6]'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff5).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1256).select([0],['Bg'])\n","\n","  #  use the QA band to mask pixels  \n","  p_qa = img.select([\"BQA\"])\n","  p_mask = p_qa.remap(qa_values,qa_values).mask().int8()\n","  \n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime);\n","  \n","  return ee.Image(both)\n","\n","def prep7bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B6_VCID_1'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[1-5]','B6_VCID_1'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff7).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1277).select([0],['Bg'])\n","  \n","  # use the QA band to mask pixels  \n","  p_qa = img.select([\"BQA\"])\n","  p_mask = p_qa.remap(qa_values,qa_values).mask().int8()\n","  \n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime);\n","  \n","  return ee.Image(both)\n","\n","def prep8bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B10'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[2-6]','B10'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff8).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1324).select([0],['Bg'])\n","  \n","  # use the QA band to mask pixels  \n","  p_qa = img.select([\"BQA\"]);\n","  p_mask = p_qa.remap(qa_val_8,qa_val_8).mask().int16()\n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime);\n","  \n","  return ee.Image(both)\n","\n","def atmosCorr(img):\n","  img = ee.Image(img)\n","  systime = img.get('system:time_start')\n","  crs_out = img.select(0).projection()\n","  \n","  radi = img.select('radi')\n","  bt = img.select('bt')\n","  Bg = img.select('Bg')\n","  \n","  gamma_top = bt.multiply(bt)\n","  gamma_bot = radi.multiply(Bg)\n","  gamma = gamma_top.divide(gamma_bot).select([0],['gamma'])\n","  \n","  delta_right = gamma_top.divide(Bg)\n","  delta = bt.subtract(delta_right).select([0],['delta'])\n","  \n","  # THIS GETS THE CORRESPONDING VAPOR IMAGE\n","  v = ee.Image(img.get('vapor')).multiply(0.1).select([0],['vapor'])\n","  \"\"\"Since the literature says that the SC algorithm doesn't work well\n","  with water vapor columns over 2.5g/cm, those pixels are removed\"\"\"\n","  v = v.mask(v.lte(2.5))\n","  \n","  img = img.addBands(v)\n","  \n","  psi_1 = img.expression(\n","    '(c1*v*v)+(c2*v)+c3',{\n","      'c1': img.select('c11'),\n","      'c2': img.select('c12'),\n","      'c3': img.select('c13'),\n","      'v': img.select('vapor')\n","    }).select([0],['psi_1'])\n","    \n","  psi_2 = img.expression(\n","    '(c1*v*v)+(c2*v)+c3',{\n","      'c1': img.select('c21'),\n","      'c2': img.select('c22'),\n","      'c3': img.select('c23'),\n","      'v': img.select('vapor')\n","    }).select([0],['psi_2'])\n","  \n","  psi_3 = img.expression(\n","    '(c1*v*v)+(c2*v)+c3',{\n","      'c1': img.select('c31'),\n","      'c2': img.select('c32'),\n","      'c3': img.select('c33'),\n","      'v': img.select('vapor')\n","    }).select([0],['psi_3'])\n"," \n","  surface_temp = psi_1.multiply(radi).add(psi_2).multiply(e).add(psi_3).multiply(gamma).add(delta)\n","\n","  surface_temp = ee.Image(surface_temp).setDefaultProjection(crs_out,None,30)\n","  surface_temp = ee.Image(surface_temp).select([0],['surface_temp']).copyProperties(img)\n","  surface_temp = surface_temp.set('system:time_start',systime)\n","\n","  return surface_temp\n","\n","print(\"Functions imported\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNfwmnT3AUL_","cellView":"form"},"source":["#@title Calculate emissivity\n","#@markdown __Run this block__ to calculate average emissivity values by using ASTER Global Emissivity Dataset (100m)<br>\n","#@markdown More information on the emissivity dataset can be found <a href=\"https://lpdaac.usgs.gov/products/ag100bv003/\" target=\"_blank\">here</a>\n","aster13 = ag100.select(['emissivity_band13']).multiply(0.001).reduceRegion(reducer=ee.Reducer.mean(), geometry=geo, scale=100).get('emissivity_band13')\n","aster14 = ag100.select(['emissivity_band14']).multiply(0.001).reduceRegion(reducer= ee.Reducer.mean(), geometry= geo, scale=100).get('emissivity_band14')\n","\n","emissivity = ee.Number.expression('(e13 + e14) / 2', {\n","  'e13': aster13,\n","  'e14': aster14\n","})\n","e = ee.Number(1).divide(ee.Number(emissivity))\n","print(f'Average emissivity: {emissivity.getInfo()}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TjyRw18ttpV","cellView":"form"},"source":["#@title Filter and Stack Landsat\n","\n","#@markdown __Run this block__ to filter by total cloud cover, date, site location, \n","#@markdown and make sure all landsat scenes are in descending orbit (wrs<234), \n","#@markdown then create radiance band, toa brightness temp band in Celcius, & band \n","#@markdown coefficients and constants. Stack them together, and make sure the metadata \n","#@markdown and system time carries over. For landsat 8, make sure scenes are \n","#@markdown nadir and the TIRS algorithm isn't preliminary version.\n","\n","l4 = (l4t1.merge(l4t2).filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep4bands))\n","\n","l5 = (l5t1.merge(l5t2).filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep5bands))\n","\n","l7 = (l7t1.merge(l7t2).filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep7bands))\n","\n","l8 = (l8t1.merge(l8t2).filterMetadata('NADIR_OFFNADIR','equals','NADIR') \\\n","      .filterMetadata('TIRS_SSM_MODEL','not_equals','PRELIMINARY') \\\n","      .filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep8bands))\n","\n","# filtering by solar zenith angle is useful in high-latitude areas\n","landsat = ee.ImageCollection((l4).merge(l5).merge(l7).merge(l8)).filterMetadata('sza','less_than',77).sort('system:time_start')\n","print(\"Landsat compiled at\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8btX84p2Q_bK","cellView":"form"},"source":["#@title Join Landsat scene to water column vapor\n","#@markdown This connects the <a href=\"https://doi.org/10.1175/1520-0477(1996)077%3C0437:TNYRP%3E2.0.CO;2\" target=\"_blank\">NCEP/NCAR</a> water column vapor image to the Landsat image so that there is a value available for atmospheric water vapor during atmospheric correction.<p>\n","#@markdown __Run this block__ to use image timestamps to find the vapor image closest in time to \n","#@markdown Landsat flyover time. This also uses geometry to find a vapor image \n","#@markdown that intersects.\n","primary = landsat  # primary collection to use\n","secondary = vapor  # collection used to join to primary\n","timeDiff = 1000*60*60*6  # maximum time difference of acquisitions in milliseconds (6 hours)\n","maxDiffFilter = ee.Filter.maxDifference(difference=timeDiff, leftField=\"system:time_start\", rightField=\"system:time_start\")\n","intersectFilter = ee.Filter.intersects(leftField=\".geo\",rightField=\".geo\")  # images must overlap\n","joinFilter = ee.Filter.And(maxDiffFilter,intersectFilter)\n","saveFirstJoin = ee.Join.saveBest(matchKey=\"vapor\", measureKey=\"difference\")\n","joinedVapor = saveFirstJoin.apply(primary,secondary,joinFilter)\n","print(\"Landsat and NCEP/NCAR water vapor joined to Landsat:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"thp8aktYX-7M","cellView":"form"},"source":["#@title Apply atmospheric correction and get skin temperature\n","#@markdown __Run this block__ to calculate water body skin temp, populate image\n","#@markdown metadata, and filter Landsat to include minimum lake coverage\n","#@markdown (defined in <a href=\"https://colab.research.google.com/drive/1AJFnCB7B7Uev2-0hqIayOb5fkSB0Xn8v#scrollTo=V1ljgJffQF1Y&line=3&uniqifier=1\">this code block</a>)\n","\n","# Calculate skin temperature\n","temps = joinedVapor.map(atmosCorr)\n","print(\"Landsat skin temperatures calculated:\", strftime(\"%x %X\"))\n","\n","'''\n","Add metadata to each scene that indicates how many visible pixels were included \n","in analysis, and filter images so that only scenes with the minimum number of \n","pixels remain.\n","'''\n","def countPixels(img):\n","  img = ee.Image(img)\n","  getCount = img.reduceRegion(**{\n","      \"reducer\": ee.Reducer.count(),\n","      \"geometry\": geo, \n","      \"scale\": 30})\n","  count = ee.Dictionary(getCount).get('surface_temp')\n","  return img.set('pixel_count',count)\n","\n","countedPixels = temps.map(countPixels).filterMetadata('pixel_count','not_less_than', pixel_min)\n","print(\"Landsat filtered:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4FleAQ6cyfch"},"source":["# Data Exploration\n","The code blocks in the following section allow you to explore your results using dataframes and pixel-value distributions. You can visually inspect each scene for errant data or export the data to explore further."]},{"cell_type":"code","metadata":{"id":"i8K6XN2xZMjP","cellView":"form"},"source":["#@title Convert data from server-side EE objects to client-side Python objects\n","#@markdown __Run this block__ to define functions for data exploration\n","def generate_histogram(img):\n","  img = ee.Image(img)\n","  fhisto = img.reduceRegion(**{\n","      \"reducer\": ee.Reducer.fixedHistogram(0,25,50).unweighted(),\n","      \"geometry\": geo,\n","      \"scale\": 30,\n","      \"maxPixels\": 5e9\n","  })\n","  return img.set('histogram',fhisto.get('surface_temp'))\n","print(\"Will generate histograms with a fixed x-axis between 0-25 deg C\")\n","\n","# These functions convert image pixels to numpy arrays\n","def createArrays(img):\n","  psi_prop = ee.Image(img).sampleRectangle(region=geo, defaultValue=9999)\n","  getProp = psi_prop.get(\"psi_1\")\n","  return img.set(\"img_array\", getProp)\n","\n","def getArrays(client_img_col):\n","  list_of_arrays = []\n","  for img in client_img_col:\n","    prop = img[\"properties\"][\"img_array\"]\n","    a = np.array(prop)\n","    list_of_arrays.append(a)\n","  return list_of_arrays"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InafBTf5ZvAS","cellView":"form"},"source":["#@markdown This code block executes the functions from the previous block and \n","#@markdown converts the image collection from a server-side EE object to a client-side \n","#@markdown Python object. This allows iteration over the image collection with a `for` \n","#@markdown loop, which provides much more Python functionality.<p><mark>__This step \n","#@markdown could take some time to run</mark> depending on the length of the \n","#@markdown ImageCollection.__\n","print(\"Start:\", strftime(\"%x %X\"))\n","imgs_histo = countedPixels.map(generate_histogram)\n","generate_arrays = imgs_histo.map(createArrays)\n","\n","imgCol = generate_arrays.getInfo()[\"features\"]\n","print(\"Finish:\", strftime(\"%x %X\"))\n","print(\"Number of Landsat scenes: \", len(imgCol))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-cobA_BbwRK","cellView":"form"},"source":["#@markdown Now that the image collection is client-side, __run this block__ to \n","#@markdown get arrays of each image.\n","# returns a list of arrays\n","imgs_to_arrays = getArrays(imgCol)\n","print(\"Converted images to arrays\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9sJyjsi9eCF","cellView":"form"},"source":["#@title View and export collated pixel distributions\n","#@markdown __Run this block__ to iterate through the image collection and convert \n","#@markdown all bins and frequencies to a single Pandas `DataFrame`. \n","#@markdown This returns *bins* (in deg C) in the first column, the image date as \n","#@markdown all subsequent column headers, and the pixel counts within each bin.\n","\n","length_plots = len(imgCol)\n","list_of_dfs = []\n","list_of_uids = []\n","# fig = make_subplots(rows=length_plots, cols=1)\n","for i in imgCol:\n","  uid = (i['properties']['uid']).split(\"_\")[-1]\n","  list_of_uids.append(uid)\n","  histogram = i[\"properties\"].get(\"histogram\")\n","\n","  a = pd.DataFrame(histogram, columns=[\"bin\",uid]).set_index(\"bin\")\n","  # fig.add_histogram()\n","  list_of_dfs.append(a)\n","\n","appended_dfs = pd.concat(list_of_dfs,ignore_index=False, axis=1)\n","transposed_dfs = appended_dfs.T\n","data_table.DataTable(appended_dfs, include_index=True, max_columns=50, max_rows=50, num_rows_per_page=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70VebGE_KA--","cellView":"form"},"source":["#@markdown __Run this block__ to export the `DataFrame` as a csv to your Google Drive\n","\n","if not 'output_dir' in globals():\n","  output_dir = \"drive/My Drive/Colab Notebooks/\"\n","out_histo_compiled = os.path.join(output_dir, file_prefix + \"_histograms.csv\")\n","appended_dfs.to_csv(out_histo_compiled)\n","print(\"Export completed:\", out_histo_compiled)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_AbqwwDcT9j","cellView":"form"},"source":["#@title View pixel distribution using `matplotlib`\n","#@markdown __Run this block__ to generate distribution charts of lake temperature \n","#@markdown for each Landsat scene.\n","print(len(list_of_uids),\" histograms will be generated\")\n","print(\"Start:\", strftime(\"%x %X\"))\n","figure, axis = plt.subplots(len(list_of_uids),1, \n","                            figsize=(8,4*len(list_of_uids)),frameon=False, dpi=50)\n","x = appended_dfs.index\n","for row in range(0,len(list_of_uids)):\n","  uid = list_of_uids[row]\n","  y = appended_dfs[uid]\n","  axis[row].plot(x,y)\n","  axis[row].set_title(uid)\n","plt.show()\n","print(\"Finish:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1sYNsf_ndyG"},"source":["##Export to CSV"]},{"cell_type":"code","metadata":{"id":"t9STTRpLaRnD","cellView":"form"},"source":["#@markdown Execute this cell block to export a CSV containing temperature and related image metadata\n","def add_temp_flag(img):\n","  stats = img.reduceRegion(**{\n","      \"reducer\": reducers,\n","      \"geometry\": geo,\n","      \"scale\": 30,\n","      \"maxPixels\": 5e9\n","  })\n","\n","  getMin = ee.Number(ee.Dictionary(stats).get(\"surface_temp_min\"))\n","  temp_flag = ee.String(getMin.lt(0.0)) # 1=true, 0=false\n","  # add_flag_temp = ee.Algorithms.If(temp_flag.compareTo(\"1\").eq(0),flags.add(\"temp_flag\"),None)\n","  return temp_flag\n","\n","def exportWholeLakeStats(img):\n","  img = ee.Image(img).clip(geo)\n","\n","  # get statistics for skin_temperature\n","  reducers = ee.Reducer.mean().combine(**{\n","      \"reducer2\": ee.Reducer.stdDev(), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.minMax(), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.median(**{\"maxBuckets\":500, \"minBucketWidth\": 0.125}), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.skew(), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.percentile(**{\"percentiles\": [25,75], \"maxBuckets\": 500, \"minBucketWidth\": 0.125}), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.count(), \"sharedInputs\":True})\n","\n","  # retrieve image metadata for output file\n","  landsattime = img.get('system:time_start')\n","  cloudcover = img.get('CLOUD_COVER')\n","  vaporImg = ee.Image(img.get('vapor'))\n","  vaportime = vaporImg.get('system:time_start')\n","  esd = img.get(\"EARTH_SUN_DISTANCE\")\n","  elev = img.get('SUN_ELEVATION')\n","  azi = img.get('SUN_AZIMUTH')\n","  sza = img.get('sza')\n","  count = img.get('pixel_count')\n","  pctAvail = ee.Number(count).divide(totalpixels)\n","  flags = ee.List([])\n","\n","  # retrieve max water column vapor for output file\n","  vaporMath = ee.Algorithms.If(ee.Algorithms.IsEqual(vaporImg,None),-9999,vaporImg)\n","  vaporMathg = ee.Image(vaporMath).multiply(0.1)\n","\n","  getWaterCol = vaporMathg.reduceRegion(\n","      reducer=ee.Reducer.max(),\n","      geometry=geo,\n","      bestEffort=True,\n","      scale=30\n","      )\n","  waterCol = ee.Dictionary(getWaterCol).get('pr_wtr')\n","  \n","\n","  # stats = img.reduceRegion(\n","  #     reducer=ee.Reducer.mean().combine(\n","  #         reducer2=ee.Reducer.stdDev(),\n","  #         sharedInputs=True).combine(\n","  #             reducer2=ee.Reducer.minMax(),\n","  #             sharedInputs=True\n","  #         ),\n","  #   geometry=geo,\n","  #   scale=30,\n","  #   maxPixels=5e9\n","  #   )\n","  stats = img.reduceRegion(**{\n","      \"reducer\": reducers,\n","      \"geometry\": geo,\n","      \"scale\": 30,\n","      \"maxPixels\": 5e9\n","  })\n","\n","  getMin = ee.Number(ee.Dictionary(stats).get(\"surface_temp_min\"))\n","  temp_flag = ee.String(getMin.lt(0.0)) # 1=true, 0=false\n","  add_flag_temp = ee.Algorithms.If(temp_flag.compareTo(\"1\").eq(0),flags.add(\"temp_flag\"),None)\n","  \n","  # lake_mean = stats.get('surface_temp_mean')\n","  # lake_stdev = stats.get('surface_temp_stdev')\n","  # zscore = img.subtract(lake_mean).divide(lake_stdev).select([0],['zscore'])\n","\n","  # avg_zscore = zscore.reduceRegion(\n","  #     reducer=ee.Reducer.mean().combine(\n","  #         reducer2=ee.Reducer.minMax(),\n","  #         sharedInputs=True\n","  #     ),\n","  #     geometry=geo,\n","  #     scale=30,\n","  #     maxPixels=5e9\n","  # )\n","\n","  more_stats = ee.Dictionary({'pixel_count':count,\n","                              'vapor_time':vaportime,\n","                              'landsat_time':landsattime,\n","                              'cloud_cover':cloudcover,\n","                              'water_column':waterCol,\n","                              'emiss':emissivity,\n","                              'elev':elev,\n","                              'azimuth':azi,\n","                              'esd':esd,\n","                              'sza':sza,\n","                              # 'flags':add_flag_temp,\n","                              'pct_lake':pctAvail,\n","                              'l_exceltime':ee.Number(landsattime).divide(1000.0).divide(86400).add(25569),\n","                              'v_exceltime': ee.Number(vaportime).divide(1000.0).divide(86400).add(25569)\n","                              # 'zscores': avg_zscore\n","                              })\n","  # stats = ee.Dictionary.combine(stats,avg_zscore)\n","  stats2 = ee.Dictionary.combine(stats, more_stats)\n","  \n","  return ee.Feature(None,stats2)\n","\n","# truncate folder path for ee export to drive\n","export_folder = output_dir.split(\"MyDrive/\",1)[1] \n","\n","export_task = ee.batch.Export.table.toDrive(**{\n","    'collection': temp_stats,\n","    'description': (file_prefix + \"_temp_stats\"),\n","    \"fileFormat\": \"CSV\",\n","    'folder': export_folder\n","})\n","\n","print(\"Exporting lake-specific 'temp_stats.csv'\")\n","export_task.start()\n","print('Polling for task (id: {}) at'.format(export_task.id))\n","\n","while export_task.active():\n","  print(strftime(\"%x %X\"), export_task.status())\n","  sleep(10)\n","\n","print(\"Finished:\", strftime(\"%x %X\"))\n","print('Export should now be visible in Drive.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwQy0u2IkEE5","cellView":"form"},"source":["#@markdown XX being edited XX Execute this cell block to export a CSV containing temperature and related image metadata\n","\n","def exportWholeLakeStats(img):\n","  img = ee.Image(img).clip(geo)\n","\n","  # get statistics for skin_temperature\n","  reducers = ee.Reducer.mean().combine(**{\n","      \"reducer2\": ee.Reducer.stdDev(), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.minMax(), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.median(**{\"maxBuckets\":500, \"minBucketWidth\": 0.125}), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.skew(), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.percentile(**{\"percentiles\": [25,75], \"maxBuckets\": 500, \"minBucketWidth\": 0.125}), \"sharedInputs\":True}).combine(**{\n","      \"reducer2\": ee.Reducer.count(), \"sharedInputs\":True})\n","\n","  # retrieve image metadata for output file\n","  landsattime = img.get('system:time_start')\n","  cloudcover = img.get('CLOUD_COVER')\n","  vaporImg = ee.Image(img.get('vapor'))\n","  vaportime = vaporImg.get('system:time_start')\n","  esd = img.get(\"EARTH_SUN_DISTANCE\")\n","  elev = img.get('SUN_ELEVATION')\n","  azi = img.get('SUN_AZIMUTH')\n","  sza = img.get('sza')\n","  count = img.get('pixel_count')\n","  pctAvail = ee.Number(count).divide(totalpixels)\n","  flags = ee.List([])\n","\n","  # retrieve max water column vapor for output file\n","  vaporMath = ee.Algorithms.If(ee.Algorithms.IsEqual(vaporImg,None),-9999,vaporImg)\n","  vaporMathg = ee.Image(vaporMath).multiply(0.1)\n","\n","  getWaterCol = vaporMathg.reduceRegion(\n","      reducer=ee.Reducer.max(),\n","      geometry=geo,\n","      bestEffort=True,\n","      scale=30\n","      )\n","  waterCol = ee.Dictionary(getWaterCol).get('pr_wtr')\n","  \n","\n","  # stats = img.reduceRegion(\n","  #     reducer=ee.Reducer.mean().combine(\n","  #         reducer2=ee.Reducer.stdDev(),\n","  #         sharedInputs=True).combine(\n","  #             reducer2=ee.Reducer.minMax(),\n","  #             sharedInputs=True\n","  #         ),\n","  #   geometry=geo,\n","  #   scale=30,\n","  #   maxPixels=5e9\n","  #   )\n","  stats = img.reduceRegion(**{\n","      \"reducer\": reducers,\n","      \"geometry\": geo,\n","      \"scale\": 30,\n","      \"maxPixels\": 5e9\n","  })\n","\n","  getMin = ee.Number(ee.Dictionary(stats).get(\"surface_temp_min\"))\n","  temp_flag = ee.String(getMin.lt(0.0)) # 1=true, 0=false\n","  add_flag_temp = ee.Algorithms.If(temp_flag.compareTo(\"1\").eq(0),flags.add(\"temp_flag\"),None)\n","  \n","  # lake_mean = stats.get('surface_temp_mean')\n","  # lake_stdev = stats.get('surface_temp_stdev')\n","  # zscore = img.subtract(lake_mean).divide(lake_stdev).select([0],['zscore'])\n","\n","  # avg_zscore = zscore.reduceRegion(\n","  #     reducer=ee.Reducer.mean().combine(\n","  #         reducer2=ee.Reducer.minMax(),\n","  #         sharedInputs=True\n","  #     ),\n","  #     geometry=geo,\n","  #     scale=30,\n","  #     maxPixels=5e9\n","  # )\n","\n","  more_stats = ee.Dictionary({'pixel_count':count,\n","                              'vapor_time':vaportime,\n","                              'landsat_time':landsattime,\n","                              'cloud_cover':cloudcover,\n","                              'water_column':waterCol,\n","                              'emiss':emissivity,\n","                              'elev':elev,\n","                              'azimuth':azi,\n","                              'esd':esd,\n","                              'sza':sza,\n","                              # 'flags':add_flag_temp,\n","                              'pct_lake':pctAvail,\n","                              'l_exceltime':ee.Number(landsattime).divide(1000.0).divide(86400).add(25569),\n","                              'v_exceltime': ee.Number(vaportime).divide(1000.0).divide(86400).add(25569)\n","                              # 'zscores': avg_zscore\n","                              })\n","  # stats = ee.Dictionary.combine(stats,avg_zscore)\n","  stats2 = ee.Dictionary.combine(stats, more_stats)\n","  \n","  return ee.Feature(None,stats2)\n","\n","temp_stats = countedPixels.map(exportWholeLakeStats)\n","\n","export_task = ee.batch.Export.table.toDrive(**{\n","    'collection': temp_stats,\n","    'description': \"temp_stats\",\n","    \"fileFormat\": \"CSV\",\n","    'folder': \"Colab Notebooks\"\n","})\n","\n","print(\"Exporting 'temp_stats.csv'\")\n","export_task.start()\n","print('Polling for task (id: {}) at'.format(export_task.id))\n","\n","while export_task.active():\n","  print(strftime(\"%x %X\"), export_task.status())\n","  sleep(10)\n","\n","print(\"Finished:\", strftime(\"%x %X\"))\n","print('Export should now be visible in Drive.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1UdYNpRcmsw"},"source":["# Get Skin Surface Temperature for specific locations\n","This section extracts skin temperature data for specific locations."]},{"cell_type":"markdown","metadata":{"id":"1zhMxo32fmnT"},"source":["# Pair Landsat with *insitu* data\n","This next section is optional, but allows you to compare any field data you may have to the Landsat data produced here. This section uses the CSV exported above (`\"/content/drive/MyDrive/Colab Notebooks/temp_stats.csv\"`)<p>\n","In order for this to run successfully, your data must be in CSV format and have the following headers/columns:\n","\n","\n","*  `datetime`: Date and time of each temperature reading with `strftime` format\n","*  `lat_dd`: latitude in decimal degrees\n","*  `lon_dd`: longitude in decimal degrees\n","*  `temp_degC`: an integer or float number representing temperature in degrees Celcius\n","*  `location`: for in-lake statistics, a column with lake zone names (string format, no special characters); can be all the same for a single output or differentiated by lake zones/sensors\n","\n","The file may have additional columns, but the above are mandatory fields. \n"]},{"cell_type":"markdown","metadata":{"id":"APg3jpUagGTf"},"source":["## Upload CSV of *insitu* data\n","Choose Option 1 or 2. For more ways to import data, see [here](https://colab.research.google.com/notebooks/io.ipynb)  "]},{"cell_type":"code","metadata":{"id":"7X-Eyd1aFf7_","cellView":"form"},"source":["#@title Option 1: Link to raw CSV from Github\n","pasted_path = \"https://raw.githubusercontent.com/cherrickunh/ids-ne-lakes/master/data/insitu_temp_data_v2021-05-17.csv?token=AHVGWKVD3LZI3UZOCDOI3ADAX66JW\" #@param {type:\"string\"}\n","is_df = pd.read_csv(pasted_path)\n","print(\"dataframe created\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RM5LPVhN6Dc3","cellView":"form"},"source":["#@title Option 2: Upload data from your local file system to Colab\n","#@markdown (temporary while connected to current Colab runtime session)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHul1TwpD-go","cellView":"form"},"source":["#@markdown Run this cell to upload a file\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print(\"Paste this in the box below:\\n/content/{name}\".format(name=fn))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52agyeVcKb8Z","cellView":"form"},"source":["pasted_path = \"/content/all_temp_data_v2021Apr21.csv\" #@param {type:\"string\"}\n","is_df = pd.read_csv(pasted_path)\n","print(\"dataframe created\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8-8OnqtaOda-"},"source":["## View data on a map"]},{"cell_type":"code","metadata":{"id":"YAZJ1hv3OwpZ"},"source":["# Coming Soon"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JnJU34MEO1c-"},"source":["## Pair *insitu* data with Landsat data"]},{"cell_type":"code","metadata":{"id":"P0Gg7oRYPGqF"},"source":["#@markdown Enter the window of time (in minutes) from Landsat flyover where *insitu* data should be included. For example, `timewindow = 30` will include any data within 60 minutes of Landsat flyover (+/- 30 minutes)\n","timewindow = 30 #@param {type:\"number\"}\n","#@markdown What timezone is your data?\n","insitu_timezone = \"US/Eastern\" #@param {type:\"string\"}\n","#@markdown Does your data observe Daylight Savings Time?\n","dst_obs = \"no\" #@param [\"yes\",\"no\"]\n","#@markdown How is your datetime formatted? (https://strftime.org/)\n","datetime_format = \"%Y-%m-%d %H:%M:%S\" #@param {type:\"string\"}\n","\n","outfile = (file_prefix + '_insitu_landsat_paired.csv')\n","cwd = output_dir\n","os.chdir(cwd)\n","\n","print(f\"Time window: +- {timewindow} minutes\")\n","print(f\"Time Zone: {insitu_timezone}\")\n","if dst_obs==\"no\":\n","  print(\"insitu data does not observe DST\")\n","else:\n","  print(\"insitu data does observe DST\")\n","print(\"Output file:\", os.path.join(cwd,outfile))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"NMJMV5vTPL8x"},"source":["#@markdown (If you're unsure of how to format your timezone, run this cell for a list of options)\n","for each in pytz.all_timezones:\n","  print(each)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2csZXUp0Zlo","cellView":"form"},"source":["#@markdown The following code block manages differences in time between \n","#@markdown UTC (Landsat data) and insitu data. It also confirms how DST \n","#@markdown should be considered.\n","min_ms = timewindow * 60 * 1000.0\n","insitu_time = pytz.timezone(insitu_timezone)\n","dst_transitions = insitu_time._utc_transition_times\n","epoch = insitu_time.localize(datetime.fromtimestamp(0))\n","utc = pytz.timezone(\"UTC\")\n","\n","def convert_datetime(dt, dtformat=datetime_format):\n","# def convert_datetime(dt, dtformat=\"%Y-%m-%d %H:%M:%S\"):\n","    \"\"\"converts string format insitu time to epoch ms\"\"\"\n","    dto = datetime.strptime(dt, dtformat)\n","\n","    if dst_obs==\"no\":\n","        dst_dates = []\n","        for item in dst_transitions:\n","            if item.year == dto.year:\n","                dst_dates.append(item)\n","\n","        if dst_dates[0] <= dto <= dst_dates[1]:\n","            dto = datetime.strptime(dt, dtformat) + timedelta(hours=1)\n","\n","    aware = insitu_time.localize(dto)\n","    return (aware - epoch).total_seconds() * 1000.0\n","\n","print(\"Date/time function imported\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnRtvL1d1-Gm"},"source":["#@markdown The following codeblock compares the datasets and generate statistics \n","#@markdown for in-lake data that matches Landsat flyovers.<br> \n","#@markdown It also uses a subfolder called 'ancillary' (and creates the folder if needed) \n","#@markdown that keeps a record of any insitu data points that are used for each Landsat scene.\n","\n","\n","\n","print(\"Start:\", strftime(\"%x %X\"))\n","gee_csv = pd.read_csv((output_dir + '/' + file_prefix + '_temp_stats.csv'))\n","gee_csv = gee_csv.drop([\".geo\"], axis=1)\n","insitu_csv = is_df\n","\n","insitu_csv[\"datetime_ms\"] = insitu_csv[\"datetime\"].apply(convert_datetime)\n","\n","for index, each in gee_csv.iterrows():\n","    scene = gee_csv.loc[index, \"system:index\"].split(\"1_\")[-1]\n","    landsattime = gee_csv.loc[index, \"landsat_time\"]\n","\n","    same_time = insitu_csv[\n","        (abs(landsattime - insitu_csv.datetime_ms) <= min_ms)]\n","\n","    gee_csv.loc[index, \"scene\"] = scene\n","    gee_csv.loc[index, \"temp_avg\"] = same_time[\"temp_degC\"].mean()\n","    gee_csv.loc[index, \"t_stdev\"] = same_time[\"temp_degC\"].std()\n","    gee_csv.loc[index, \"depth_avg\"] = same_time[\"depth_m\"].mean()\n","    gee_csv.loc[index, \"d_stdev\"] = same_time[\"depth_m\"].std()\n","    gee_csv.loc[index, \"temp_med\"] = same_time[\"temp_degC\"].median()\n","    gee_csv.loc[index, \"insitu_count\"] = same_time.shape[0]\n","\n","    site_stats = same_time.groupby(['location'])['temp_degC'].agg(['median', 'mean', 'std', 'count'])\n","\n","    sites = site_stats.axes[0]\n","    stats = site_stats.axes[1]\n","\n","    for site in sites:\n","        for stat in stats:\n","            newcol = \"{0}_{1}\".format(str(site), str(stat))\n","            gee_csv.loc[index, newcol] = site_stats[stat][site].item()\n","    \n","    if same_time.shape[0] > 0:\n","        if not os.path.exists(os.path.join(cwd, 'ancillary')):\n","            os.makedirs(os.path.join(cwd, 'ancillary'))\n","        same_time.to_csv(os.path.join(cwd, 'ancillary', scene + \".csv\"))\n","\n","out_csv = gee_csv[gee_csv[\"insitu_count\"] > 0]\n","out_csv.to_csv(os.path.join(cwd, outfile))\n","(\"Finished:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]}]}