{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C1_SCA_v2_18Oct2021.ipynb","private_outputs":true,"provenance":[{"file_id":"1SNyzXBRlWx-WEfxFPeS8DZDgkSYwVwsi","timestamp":1632153555668},{"file_id":"1AJFnCB7B7Uev2-0hqIayOb5fkSB0Xn8v","timestamp":1621379474639},{"file_id":"1U_O3YgDRCNrZCAWCdL0X1Z422cu4Oo6I","timestamp":1620745209104}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tr9ipVEDv7BK"},"source":["*Version 3*<br>\n","*Last updated: 2021-11-15<p>*\n","christina.herrick@unh.edu<br>\n","steeleb@caryinstitute.org<br>\n","__Please do not distribute__\n","\n","This colab notebook used deprecated Collection 1 GEE layers. Use with caution. Additionally, there are hard-coded folder paths at use in this Colab notebook. "]},{"cell_type":"markdown","metadata":{"id":"psnrRlTjBj2M"},"source":["# Initial Setup\n","\n","This notebook uses the [Google Earth Engine](https://developers.google.com/earth-engine) [Python API](https://developers.google.com/earth-engine/guides/python_install) to apply the Single-Channel (SC) algorithm, a model-based algorithm using atmospheric correction coefficients, to Landsat thermal imagery and derives water body skin surface temperatures. \n","\n","Algorithms for Landsat 4,5,7 can be found in *Jiménez-Muñoz, J. C., J. Cristóbal, J. A. Sobrino, G. Soria, N. Ninyerola, and X. Pons. 2009. Revision of the Single-Channel Algorithm for Land Surface Temperature Retrieval From Landsat Thermal-Infrared Data. IEEE Transactions on Geoscience and Remote Sensing 47:339–349.* [https://doi.org/10.1109/TGRS.2008.2007125](https://doi.org/10.1109/TGRS.2008.2007125)\n","\n","Algorithms for Landsat 8 can be found in *Jiménez-Muñoz, J. C., J. A. Sobrino, D. Skoković, C. Mattar, and J. Cristóbal. 2014. Land Surface Temperature Retrieval Methods From Landsat-8 Thermal Infrared Sensor Data. IEEE Geoscience and Remote Sensing Letters 11:1840–1843.* [https://doi.org/10.1109/LGRS.2014.2312032](https://doi.org/10.1109/LGRS.2014.2312032)\n"]},{"cell_type":"markdown","metadata":{"id":"y2hwVo9OVsL-"},"source":["To run this script successfully, the bounding box coordinates of a lake are entered in a Google Spreadsheet. If you need help finding those coordinates, try using [OpenStreetMap](https://www.openstreetmap.org/export#map=12/43.3826/-72.0157). The bounding box should be as small as possible while still including the entire lake surface."]},{"cell_type":"markdown","metadata":{"id":"g3zRra91DaEq"},"source":["## Modules\n","\n","This section of code blocks imports necessary python modules for the notebook to run. You will be prompted to click one or more URLs and be taken to a page to sign in with your Google account. This account must already be authorized to use Google Earth Engine. If you do not already have access, [fill out this application](https://signup.earthengine.google.com/#!/).\n","\n","Copy the unique code(s) provided on the web page when prompted and paste where prompted to finish authorization."]},{"cell_type":"code","metadata":{"id":"gh-VYdMKCAkM","cellView":"form"},"source":["#@markdown __Run this block__ to authorize Colab to authenticate your Google account and give it access to upload files from your local computer ([to be used later](https://colab.research.google.com/drive/1AJFnCB7B7Uev2-0hqIayOb5fkSB0Xn8v#scrollTo=L_Tf54wwIPRy) in the notebook). Once you paste the code, press Enter.\n","from google.colab import auth, files\n","auth.authenticate_user()\n","import gspread\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STd1_lFcVYMZ","cellView":"form"},"source":["#@markdown __Run this block__ to connect colab to your Google Earth Engine account\n","import ee\n","ee.Authenticate()\n","ee.Initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaB_g_reJG41","cellView":"form"},"source":["#@markdown Connect Colab to your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SN2nSfHBF1S","cellView":"form"},"source":["#@markdown Run this block to install packages and functions used for interactive mapping (double-click to reveal code)\n","import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from time import strftime, sleep\n","from datetime import datetime, timedelta\n","import pytz\n","import folium\n","from folium import plugins\n","\n","# Add custom basemaps to folium\n","basemaps = {\n","    'Google Maps': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Maps',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Google Satellite': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Satellite',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Google Terrain': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Terrain',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Google Satellite Hybrid': folium.TileLayer(\n","        tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n","        attr = 'Google',\n","        name = 'Google Satellite',\n","        overlay = True,\n","        control = True\n","    ),\n","    'Esri Satellite': folium.TileLayer(\n","        tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n","        attr = 'Esri',\n","        name = 'Esri Satellite',\n","        overlay = True,\n","        control = True\n","    )\n","}\n","\n","# Define a method for displaying Earth Engine image tiles on a folium map.\n","def add_ee_layer(self, ee_object, vis_params, name):\n","    \n","    try:    \n","        # display ee.Image()\n","        if isinstance(ee_object, ee.image.Image):    \n","            map_id_dict = ee.Image(ee_object).getMapId(vis_params)\n","            folium.raster_layers.TileLayer(\n","            tiles = map_id_dict['tile_fetcher'].url_format,\n","            attr = 'Google Earth Engine',\n","            name = name,\n","            overlay = True,\n","            control = True\n","            ).add_to(self)\n","        # display ee.ImageCollection()\n","        elif isinstance(ee_object, ee.imagecollection.ImageCollection):    \n","            ee_object_new = ee_object.mosaic()\n","            map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n","            folium.raster_layers.TileLayer(\n","            tiles = map_id_dict['tile_fetcher'].url_format,\n","            attr = 'Google Earth Engine',\n","            name = name,\n","            overlay = True,\n","            control = True\n","            ).add_to(self)\n","        # display ee.Geometry()\n","        elif isinstance(ee_object, ee.geometry.Geometry):    \n","            folium.GeoJson(\n","            data = ee_object.getInfo(),\n","            name = name,\n","            overlay = True,\n","            control = True\n","        ).add_to(self)\n","        # display ee.FeatureCollection()\n","        elif isinstance(ee_object, ee.featurecollection.FeatureCollection):  \n","            ee_object_new = ee.Image().paint(ee_object, 0, 2)\n","            map_id_dict = ee.Image(ee_object_new).getMapId(vis_params)\n","            folium.raster_layers.TileLayer(\n","            tiles = map_id_dict['tile_fetcher'].url_format,\n","            attr = 'Google Earth Engine',\n","            name = name,\n","            overlay = True,\n","            control = True\n","        ).add_to(self)\n","    \n","    except:\n","        print(\"Could not display {}\".format(name))\n","    \n","# Add EE drawing method to folium.\n","folium.Map.add_ee_layer = add_ee_layer\n","\n","print(\"Packages installed\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1C4zmuTIA8SR"},"source":["## Imported variables"]},{"cell_type":"code","metadata":{"id":"CkiZcezXBEG5","cellView":"form"},"source":["#@markdown Run this block to import pre-existing features, images, and collections from Earth Engine (double-click to reveal code)\n","wrs2 = ee.FeatureCollection(\"users/christinaherrickunh/WRS2_descending_2018\")\n","utmbounds = ee.FeatureCollection(\"users/christinaherrickunh/UTM_Zone_Boundaries\")\n","sw = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\")\n","ag100 = ee.Image(\"NASA/ASTER_GED/AG100_003\")\n","vapor = ee.ImageCollection(\"NCEP_RE/surface_wv\")\n","l4t1 = ee.ImageCollection(\"LANDSAT/LT04/C01/T1\")\n","l4t2 = ee.ImageCollection(\"LANDSAT/LT04/C01/T2\")\n","l5t1 = ee.ImageCollection(\"LANDSAT/LT05/C01/T1\")\n","l5t2 = ee.ImageCollection(\"LANDSAT/LT05/C01/T2\")\n","l7t1 = ee.ImageCollection(\"LANDSAT/LE07/C01/T1\")\n","l7t2 = ee.ImageCollection(\"LANDSAT/LE07/C01/T2\")\n","l8t1 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1\")\n","l8t2 = ee.ImageCollection(\"LANDSAT/LC08/C01/T2\")\n","\n","print(\"variables installed\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkoErj-_1wN1"},"source":["Below are atmospheric functions derived from modeling the [TIGR2311](https://doi.org/10.1175/1520-0450(2002)041%3C0144:ARNNAF%3E2.0.CO;2) atmospheric sounding database, except Landsat 8, which come from [GAPRI4838](http://dx.doi.org/10.1080/01431161.2015.1054965). These are necessary for the Single-Channel algorithm to run successfully. "]},{"cell_type":"code","metadata":{"id":"SxNwes53kc4U"},"source":["coeff4 = [0.06674,-0.03447,1.04483,-0.50095,-1.15652,0.09812,-0.04732,1.50453,-0.34405] #  TIGR2311\n","coeff5 = [0.08158,-0.05707,1.05991,-0.58853,-1.08536,-0.00448,-0.06201,1.59086,-0.33513] #  TIGR2311\n","coeff7 = [0.06982,-0.03366,1.04896,-0.51041,-1.20026,0.10490,-0.05457,1.52631,-0.32136] #  TIGR2311\n","coeff8 = [0.04019,0.02916,1.01523,-0.38333,-1.50294,0.20324,0.00918,1.36072,-0.27514] #  GAPRI4838"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4d-W11qiD-U"},"source":["\n","Landsat scenes contain a QA band meant for bitwise masking of pixels. Information can be found at [USGS](https://www.usgs.gov/core-science-systems/nli/landsat/landsat-collection-1-level-1-quality-assessment-band?qt-science_support_page_related_con=0#qt-science_support_page_related_con). \n","\n","Below are lists of binary pixel values used for quality control, represented as `qa_values` (Landsat 4,5,7) and as `qa_val_8` (Landsat 8). Cloud, snow, and ice pixels are removed.\n","\n","Excel spreadsheets of pixel quality values and their definititions can be found:\n","- for Landat 4-7 [here](https://unh.box.com/v/landsat4-7-qavalues); \n","- for Landsat 8, [here](https://unh.box.com/v/landsat8-qavalues)"]},{"cell_type":"code","metadata":{"id":"to3lDRUviGuD"},"source":["qa_values = ee.List([672,676,680,684,704,708,712,716,928,932,936,940,960,964,968,972]) #  KEEP these pixel values\n","                        # 1696,1700,1704,1708,1728,1732,1736,1740]) <-- these are snow/ice\n","\n","qa_val_8 = ee.List([2,2720,2722,2724,2728,2732,2752,2756,2760,2764,2976,2980,2984,2988,3008,3012,3016,3020]) #  KEEP these pixel values\n","                        # ,3744,3748,3752,3756,3776,3780,3784,3788]); <-- these are snow/ice"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxgpEciUBKLy"},"source":["## User-set variables\n","\n","In this section, use either *Option A*, where you define the bounding box, or *Option B* where you import a shape file of your lake. If you are using *Option A*, make sure that the *Option B* section is set to 'no'.\n","\n","The final section, *Set Remaining Variables*, defines acceptable lake coverage percent, RMSE of Landsat Tier 2 inclusion, dates of interest, and path/row of Landsat flyover."]},{"cell_type":"markdown","metadata":{"id":"9JiuNetjpgpJ"},"source":["###Option A: use a bounding box\n","If you need help finding your coordinates, try using [OpenStreetMap](https://www.openstreetmap.org/export#map=12/43.3826/-72.0157). The bounding box should be as small as possible while still including the entire lake surface.<p>\n","Enter coordinates to see a map of the bounding box. You can also click on the map to get interactive pop-ups of the latitude (y) and longitude (x), and replace/re-run the coordinates."]},{"cell_type":"code","metadata":{"id":"eQX8qmNz_aLM","cellView":"form"},"source":["#@markdown `lat1` = North\n","lat1 = '43.4463'  #@param {type:\"string\"}\n","#@markdown `lat2` = South\n","lat2 = '43.3177'  #@param {type:\"string\"}\n","#@markdown `lon1` = West\n","lon1 = '-72.0882'  #@param {type:\"string\"}\n","#@markdown `lon2` = East\n","lon2 = '-72.0171'  #@param {type:\"string\"}\n","\n","use_user_input_file = \"no\"\n","lat1 = float(lat1)\n","lon1 = float(lon1)\n","lat2 = float(lat2)\n","lon2 = float(lon2)\n","box = ee.Geometry.Polygon(\n","    [[[lon1, lat1], # ur\n","      [lon2, lat1], # ul\n","      [lon2, lat2], # ll\n","      [lon1, lat2]]], None, False) # lr\n","center_lat = (lat1+lat2)/2\n","center_lon = (lon1+lon2)/2\n","locs_map = folium.Map(location=[center_lat,center_lon],zoom_start=10,width=600,height=600)\n","locs_map.add_child(folium.LatLngPopup())\n","basemaps['Google Maps'].add_to(locs_map)\n","locs_map.add_ee_layer(box,{},'aoi')\n","display(locs_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBZzaGgqpr8W"},"source":["###Option B: upload a table file"]},{"cell_type":"markdown","metadata":{"id":"adRm0pPgdcpa"},"source":["Using your Google Earth Engine account, upload a shapefile or csv of your study lake to your Assets and link to it here.<p>![upload_to_ee](https://drive.google.com/thumbnail?id=1lfFoZzQD_wAA7Bnil7mI4zwjKDG5kegh)[click here to enlarge](https://drive.google.com/file/d/1lfFoZzQD_wAA7Bnil7mI4zwjKDG5kegh/view?usp=sharing)<p> ![upload_to_ee](https://drive.google.com/thumbnail?id=1KNaZV63J_LUp6X1OcoLX1wonF0ASiIzi)[click here to enlarge](https://drive.google.com/file/d/1KNaZV63J_LUp6X1OcoLX1wonF0ASiIzi/view?usp=sharing)"]},{"cell_type":"code","metadata":{"id":"e0lONKBvqAUp","cellView":"form"},"source":["#@markdown File path should begin with 'users/'\n","user_input_file = \"\" #@param {type: \"string\"}\n","use_user_input_file = \"no\" #@param [\"yes\",\"no\"] {allow-input: true}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIKkHHMnKqik"},"source":["shp = ee.FeatureCollection(user_input_file).geometry()\n","centroid = shp.centroid(10).getInfo()[\"coordinates\"]\n","center_lat = centroid[1]\n","center_lon = centroid[0]\n","print(center_lat)\n","print(center_lon)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"93P5zojCKmwm"},"source":["shp_map = folium.Map(location=[center_lat,center_lon],zoom_start=10,width=600,height=600)\n","shp_map.add_child(folium.LatLngPopup())\n","basemaps['Google Maps'].add_to(shp_map)\n","shp_map.add_ee_layer(shp,{},'aoi')\n","display(shp_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDrkGq_jwgIo"},"source":["###Set remaining variables"]},{"cell_type":"markdown","metadata":{"id":"WM_eE99ojZtz"},"source":["Boundaries of water bodies are automatically \n","detected using the JRC Global Surface Water Mapping Layer dataset of percent water occurrence. By default, a pixel has to be classified as water at least 55% of the time. This is defined as `pctTime`\n","\n","More information on this dataset can be found at [doi:10.1038/nature20584](https://doi.org/10.1038/nature20584)\n","\n","Landsat scenes from both Tier 1 and Tier 2 of Collection 1 are included for possible use. From Tier 2, only scenes that are processed to L1T with a combined RMS error of no greater than 24 meters are considered."]},{"cell_type":"code","metadata":{"id":"RwhZWCrkVrb0","cellView":"form"},"source":["pctTime = 55  #@param {type: \"number\"}\n","rmse = 24  #@param {type: \"number\"}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_t5slRt5Q4qV"},"source":["Landsat records begin in 1984 with Landsat 4 TM. Enter the year range that you want to search, as well as months of the year. To search all months, `m1 = 1` and `m2 = 12` <p>\n","First year (y1) and last year (y2). Years are inclusive.<p>\n","First month (m1) and last month (m2). Months are inclusive."]},{"cell_type":"code","metadata":{"id":"ypJaiep9n1F7","cellView":"form"},"source":["y1 = 1980 #@param {type: \"number\"}\n","y2 = 2020 #@param {type: \"number\"}\n","\n","m1 =  5#@param {type: \"number\"}\n","m2 =  11#@param {type: \"number\"}\n","print('Script will search years %d through %d and months %d through %d of each year' % (y1,y2,m1,m2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stjrJlU2HamN","cellView":"form"},"source":["#@markdown This code block uses the extent of Option A/B to calculate the Landsat path(s) and row(s) that it overlaps. It will print as `WRS2 Path/Row: PPPRRR` where `PPP` is the three-digit path, and `RRR` is the three-digit row.\n","if use_user_input_file==\"yes\":\n","  box = shp\n","\n","pathrow = wrs2.filterBounds(box)\n","  \n","num_of_pr = len(pathrow.getInfo()[\"features\"])\n","path_west = 1\n","path_east = 233\n","row_north = 122\n","row_south = 1\n","\n","print('landsat path/rows:')\n","for i in range(0,num_of_pr):\n","  pr = pathrow.getInfo()[\"features\"][i][\"properties\"][\"PR\"]\n","  p = pr[:3]\n","  r = pr[3:]\n","  if int(p) > path_west:\n","    path_west = int(p)\n","  if int(p) < path_east:\n","    path_east = int(p)\n","  if int(r) < row_north:\n","    row_north = int(r)\n","  if int(r) > row_south:\n","    row_south = int(r)\n","  print(f\"p{p} r{r}\")\n","\n","utm = utmbounds.filterBounds(box)\n","printUTM = utm.getInfo()[\"features\"][0][\"properties\"][\"ZONE\"]\n","print(\"UTM Zone:\",printUTM, \"(does not print more than one zone if more are present)\")\n","crs_out = f\"EPSG:326{printUTM}\"\n","\n","zone_map = folium.Map(location=[center_lat,center_lon],zoom_start=7,width=600,height=600)\n","zone_map.add_child(folium.LatLngPopup())\n","basemaps['Google Maps'].add_to(zone_map)\n","zone_map.add_ee_layer(utm,{},'utm zone(s)')\n","zone_map.add_ee_layer(pathrow,{},'path row')\n","zone_map.add_ee_layer(box,{},'aoi box')\n","display(zone_map)\n","print(f'\\nbounding paths: {path_west} to {path_east}')\n","print(f'bounding rows: {row_north} to {row_south}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RI5PLatbTY1I"},"source":["Use the printed statement above to guide your entry for the path and row variables below. If there is only one path and/or one row, enter the same number for `p1,p2` and `r1,r2` <p>\n","Starting and ending path (*Path 233 starts at the Prime Meridian and decreases moving west-east*)"]},{"cell_type":"code","metadata":{"id":"XdAVBs0vRT17","cellView":"form"},"source":["#@markdown Use the printed statement above to guide your entry for the path and row variables below. If there is only one path and/or one row, enter the same number for `p1,p2` and `r1,r2` <p> \n","#@markdown Starting and ending path (*Path 233 starts at the Prime Meridian and decreases moving west-east*)\n","p1 = 13 #@param {type: \"number\"}\n","p2 =  13#@param {type: \"number\"}\n","#@markdown Starting row (*Row 1 starts in the Arctic and increases moving north-south*)\n","r1 =  30#@param {type: \"number\"}\n","r2 = 30 #@param {type: \"number\"}\n","print(f\"path {p1} to {p2}, row {r1} to {r2}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frk9zPA9P4fq"},"source":["# Automatically delineate waterbody"]},{"cell_type":"markdown","metadata":{"id":"1xE7MPgvY78u"},"source":["## Find water pixels & boundary"]},{"cell_type":"markdown","metadata":{"id":"EmC-95LV83n3"},"source":["Delineate lake boundaries using [JRC Water dataset](https://global-surface-water.appspot.com/).<p>"]},{"cell_type":"code","metadata":{"id":"V1ljgJffQF1Y"},"source":["#@markdown This code block reduces the bounding box defined above to the largest water body present, and then counts the 30m pixels within the water body.<p>\n","#@markdown Landsat scenes included in analysis must have at least 25% of (discontinuous) clear lake pixels.\n","wateroccurrence = sw.select(0).setDefaultProjection('EPSG:32618')\n","water = wateroccurrence.gte(pctTime)\n","water = water.updateMask(water.neq(0))\n","water = water\n","\n","def addArea(feature):\n","  # returns area +/- 1sqm\n","  return feature.set({'area':feature.geometry().area(1)})  \n","\n","regions = water.addBands(wateroccurrence).reduceToVectors(\n","    reducer=ee.Reducer.min(),\n","    geometry=box,\n","    scale=30,\n","    maxPixels=5e9,\n","    geometryInNativeProjection=False,\n","    labelProperty='surfaceWater').map(addArea).sort('area',False);\n","\n","lake_outline = ee.Feature(regions.first())\n","aoi = lake_outline\n","geo = lake_outline.geometry()\n","coords = geo.getInfo()['coordinates'][0]\n","\n","watercount = water.reduceRegion(reducer=ee.Reducer.count(), \n","                                geometry=lake_outline.geometry(),\n","                                scale=30, bestEffort=True)\n","totalpixels = watercount.getInfo()[\"occurrence\"]\n","pixel_min = totalpixels*0.25\n","print(\"\\n\\n# of lake pixels: \", totalpixels);\n","print(\"25% of available lake pixels is\", pixel_min)\n","\n","pixel_map = folium.Map(location=[center_lat,center_lon],zoom_start=10, width=600, height=600)\n","basemaps['Google Satellite'].add_to(pixel_map)\n","pixel_map.add_ee_layer(geo ,{},'pixels over lake')\n","display(pixel_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-EI2qW2pEsc"},"source":["## Landsat functions\n","This block of code defines functions to pre-process Landsat images in preparation for atmospheric correction to water skin temperature."]},{"cell_type":"markdown","metadata":{"id":"V8BkyW3Fs0KU"},"source":[""]},{"cell_type":"code","metadata":{"id":"Cbd6m5SRlsyF"},"source":["def prep4bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B6'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[1-6]'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff4).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1290).select([0],['Bg'])\n","\n","  #  use the QA band to mask cloudy pixels  \n","  p_qa = img.select([\"BQA\"])\n","  p_mask = p_qa.remap(qa_values,qa_values).mask().int8()\n","  \n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime)\n","  \n","  return ee.Image(both)\n","\n","def prep5bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B6'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[1-6]'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff5).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1256).select([0],['Bg'])\n","\n","  #  use the QA band to mask cloudy pixels  \n","  p_qa = img.select([\"BQA\"])\n","  p_mask = p_qa.remap(qa_values,qa_values).mask().int8()\n","  \n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime);\n","  \n","  return ee.Image(both)\n","\n","def prep7bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B6_VCID_1'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[1-5]','B6_VCID_1'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff7).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1277).select([0],['Bg'])\n","  \n","  # use the QA band to mask cloudy pixels  \n","  p_qa = img.select([\"BQA\"])\n","  p_mask = p_qa.remap(qa_values,qa_values).mask().int8()\n","  \n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime);\n","  \n","  return ee.Image(both)\n","\n","def prep8bands(img):\n","  systime = img.get('system:time_start')\n","  elev = img.get('SUN_ELEVATION')\n","  sza = ee.Number(90).subtract(elev)\n","  uid = img.get('system:index')\n","  \n","  radiance = ee.Algorithms.Landsat.calibratedRadiance(img).select(['B10'],['radi'])\n","  toa = ee.Algorithms.Landsat.TOA(img)\n","  toa = toa.select(['B[2-6]','B10'],['blue','green','red','nir','swir','temp'])\n","  \n","  bt = toa.select(['temp'],['bt']).subtract(273.15)\n","  \n","  coeff = ee.Image(coeff8).select([0,1,2,3,4,5,6,7,8],['c11','c12','c13','c21','c22','c23','c31','c32','c33'])\n","  Bg = ee.Image.constant(1324).select([0],['Bg'])\n","  \n","  # use the QA band to mask cloudy pixels  \n","  p_qa = img.select([\"BQA\"]);\n","  p_mask = p_qa.remap(qa_val_8,qa_val_8).mask().int16()\n","  both = radiance.addBands(coeff).addBands(Bg).addBands(bt).updateMask(p_mask).copyProperties(img).set('sza',sza).set('uid',uid).set('system:time_start',systime);\n","  \n","  return ee.Image(both)\n","\n","print(\"Functions imported\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45tElCUuotvD"},"source":["# Get Skin Surface Temps"]},{"cell_type":"code","metadata":{"id":"yNfwmnT3AUL_","cellView":"form"},"source":["#@title Calculate emissivity\n","#@markdown Calculate average emissivity values by using ASTER Global Emissivity Dataset (100m)\n","aster13 = ag100.select(['emissivity_band13']).multiply(0.001).reduceRegion(reducer=ee.Reducer.mean(), geometry=geo, scale=100).get('emissivity_band13')\n","aster14 = ag100.select(['emissivity_band14']).multiply(0.001).reduceRegion(reducer= ee.Reducer.mean(), geometry= geo, scale=100).get('emissivity_band14')\n","\n","emissivity = ee.Number.expression('(e13 + e14) / 2', {\n","  'e13': aster13,\n","  'e14': aster14\n","})\n","e = ee.Number(1).divide(ee.Number(emissivity))\n","print(f'Average emissivity: {emissivity.getInfo()}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KIcG4Na1W2mH"},"source":["More information on the emissivity dataset can be found [here](https://lpdaac.usgs.gov/products/ag100bv003/)"]},{"cell_type":"markdown","metadata":{"id":"0bgXnMRupkuo"},"source":["## Atmospheric correction function\n","This defines a function to process prepped Landsat images to water skin temperature."]},{"cell_type":"code","metadata":{"id":"DIIBXmYwpobI"},"source":["def atmosCorr(img):\n","  img = ee.Image(img)\n","  systime = img.get('system:time_start')\n","  crs_out = img.select(0).projection()\n","  \n","  radi = img.select('radi')\n","  bt = img.select('bt')\n","  Bg = img.select('Bg')\n","  \n","  gamma_top = bt.multiply(bt)\n","  gamma_bot = radi.multiply(Bg)\n","  gamma = gamma_top.divide(gamma_bot).select([0],['gamma'])\n","  \n","  delta_right = gamma_top.divide(Bg)\n","  delta = bt.subtract(delta_right).select([0],['delta'])\n","  \n","  # THIS GETS THE CORRESPONDING VAPOR IMAGE\n","  v = ee.Image(img.get('vapor')).multiply(0.1).select([0],['vapor'])\n","  \"\"\"Since the literature says that the algorithm doesn't work well with\n","  water vapor columns over 2.5g/cm, those pixels are removed\"\"\"\n","  v = v.mask(v.lte(2.5))\n","  \n","  img = img.addBands(v)\n","  \n","  psi_1 = img.expression(\n","    '(c1*v*v)+(c2*v)+c3',{\n","      'c1': img.select('c11'),\n","      'c2': img.select('c12'),\n","      'c3': img.select('c13'),\n","      'v': img.select('vapor')\n","    }).select([0],['psi_1'])\n","    \n","  psi_2 = img.expression(\n","    '(c1*v*v)+(c2*v)+c3',{\n","      'c1': img.select('c21'),\n","      'c2': img.select('c22'),\n","      'c3': img.select('c23'),\n","      'v': img.select('vapor')\n","    }).select([0],['psi_2'])\n","  \n","  psi_3 = img.expression(\n","    '(c1*v*v)+(c2*v)+c3',{\n","      'c1': img.select('c31'),\n","      'c2': img.select('c32'),\n","      'c3': img.select('c33'),\n","      'v': img.select('vapor')\n","    }).select([0],['psi_3'])\n"," \n","  surface_temp = psi_1.multiply(radi).add(psi_2).multiply(e).add(psi_3).multiply(gamma).add(delta)\n","  \n","  surface_temp = ee.Image(surface_temp).setDefaultProjection(crs_out,None,30)\n","  surface_temp = ee.Image(surface_temp).select([0],['surface_temp']).copyProperties(img)\n","  surface_temp = surface_temp.set('system:time_start',systime)\n","\n","  return surface_temp\n","\n","print(\"Function imported:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H49t-gA6tdtS"},"source":["## Filter and Stack Landsat\n","\n","For each landsat stack, filter by total cloud cover, date, site location, and\n","make sure all landsat scenes are in descending orbit (wrs<234), then create radiance band, \n","toa brightness temp band in Celcius, & band coefficients and constants.\n","Stack them together, and make sure the metadata and system time carries over. For landsat 8, \n","make sure scenes are nadir and the TIRS algorithm isn't preliminary version"]},{"cell_type":"code","metadata":{"id":"1TjyRw18ttpV"},"source":["l4 = (l4t1.merge(l4t2).filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep4bands))\n","\n","l5 = (l5t1.merge(l5t2).filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep5bands))\n","\n","l7 = (l7t1.merge(l7t2).filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep7bands))\n","\n","l8 = (l8t1.merge(l8t2).filterMetadata('NADIR_OFFNADIR','equals','NADIR') \\\n","      .filterMetadata('TIRS_SSM_MODEL','not_equals','PRELIMINARY') \\\n","      .filterMetadata('DATA_TYPE','equals','L1TP') \\\n","      .filterMetadata('GEOMETRIC_RMSE_MODEL','not_greater_than',rmse) \\\n","      .filterBounds(geo) \\\n","      .filter(ee.Filter.calendarRange(y1,y2,'year')) \\\n","      .filter(ee.Filter.calendarRange(m1,m2,'month')) \\\n","      .filterMetadata('WRS_ROW','not_less_than',r1).filterMetadata('WRS_ROW','not_greater_than',r2) \\\n","      .filterMetadata('WRS_PATH','not_greater_than',p1).filterMetadata('WRS_PATH','not_less_than',p2) \\\n","      .map(prep8bands))\n","\n","# filtering by solar zenith angle is useful in high-latitude areas\n","landsat = ee.ImageCollection((l4).merge(l5).merge(l7).merge(l8)).filterMetadata('sza','less_than',77).sort('system:time_start')\n","print(\"Landsat compiled at\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EivqaYrdQt2W"},"source":["## Join Landsat scene to water column vapor\n","This connects the [NCEP/NCAR](https://doi.org/10.1175/1520-0477(1996)077%3C0437:TNYRP%3E2.0.CO;2) water column vapor image to the Landsat image so that there is a value available for atmospheric water vapor during atmospheric correction.<p>\n","It uses image timestamps to find the vapor image closest in time to Landsat flyover time, and it also uses geometry to find a vapor image that intersects."]},{"cell_type":"code","metadata":{"id":"8btX84p2Q_bK"},"source":["primary = landsat  # primary collection to use\n","secondary = vapor  # collection used to join to primary\n","timeDiff = 1000*60*60*6  # maximum time difference of acquisitions in milliseconds (6 hours)\n","maxDiffFilter = ee.Filter.maxDifference(difference=timeDiff, leftField=\"system:time_start\", rightField=\"system:time_start\")\n","intersectFilter = ee.Filter.intersects(leftField=\".geo\",rightField=\".geo\")  # images must overlap\n","joinFilter = ee.Filter.And(maxDiffFilter,intersectFilter)\n","saveFirstJoin = ee.Join.saveBest(matchKey=\"vapor\", measureKey=\"difference\")\n","joinedVapor = saveFirstJoin.apply(primary,secondary,joinFilter)\n","print(\"Landsat and NCEP/NCAR water vapor joined:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KP4ADnNRP8G2"},"source":["## Apply atmospheric correction and get skin temp"]},{"cell_type":"code","metadata":{"id":"NAob0dG1P_-G"},"source":["temps = joinedVapor.map(atmosCorr)\n","print(\"Landsat skin temperatures calculated:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e_gjs4c-ZGuY"},"source":["Add metadata to each scene that indicates how many visible pixels were included in analysis, and filter images so that only scenes with the minimum number of pixels remain."]},{"cell_type":"code","metadata":{"id":"thp8aktYX-7M"},"source":["def countPixels(img):\n","  img = ee.Image(img)\n","  getCount = img.reduceRegion(**{\n","      \"reducer\": ee.Reducer.count(),\n","      \"geometry\": geo, \n","      \"scale\": 30})\n","  count = ee.Dictionary(getCount).get('surface_temp')\n","  return img.set('pixel_count',count)\n","\n","countedPixels = temps.map(countPixels).filterMetadata('pixel_count','not_less_than', pixel_min)\n","print(\"Landsat filtered:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4FleAQ6cyfch"},"source":["# Prepare data for statistical analysis"]},{"cell_type":"markdown","metadata":{"id":"INh58xshrbs9"},"source":["## Histogram function\n","Function that generates a histogram of each image in the collection"]},{"cell_type":"code","metadata":{"id":"i8K6XN2xZMjP"},"source":["def generate_histogram(img):\n","  img = ee.Image(img)\n","  fhisto = img.reduceRegion(**{\n","      \"reducer\": ee.Reducer.fixedHistogram(-5,30,350).unweighted(),\n","      \"geometry\": geo,\n","      \"scale\": 30,\n","      \"maxPixels\": 5e9\n","  })\n","  return img.set('histogram',fhisto.get('surface_temp'))\n","print(\"Will generate histograms with a fixed x-axis between -5 and 30 deg C\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzv5RDd5ruvJ"},"source":["Two functions that convert image pixels to numpy arrays"]},{"cell_type":"code","metadata":{"id":"5_rGIurtmdpB"},"source":["def createArrays(img):\n","  psi_prop = ee.Image(img).sampleRectangle(region=geo, defaultValue=9999)\n","  getProp = psi_prop.get(\"psi_1\")\n","  return img.set(\"img_array\", getProp)\n","\n","def getArrays(client_img_col):\n","  list_of_arrays = []\n","  for img in client_img_col:\n","    prop = img[\"properties\"][\"img_array\"]\n","    a = np.array(prop)\n","    list_of_arrays.append(a)\n","  return list_of_arrays"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InafBTf5ZvAS"},"source":["#@markdown This code block executes the above `array` functions on the image collection and convert the image collection from a server-side object to a client-side object. This allows iteration over the image collection with a `for` loop, which provides much more Python functionality.<p>__This step could take some time to run depending on the length of the ImageCollection.__\n","print(\"Start:\", strftime(\"%x %X\"))\n","imgs_histo = countedPixels.map(generate_histogram)\n","generate_arrays = imgs_histo.map(createArrays)\n","\n","imgCol = generate_arrays.getInfo()[\"features\"]\n","print(\"Finish:\", strftime(\"%x %X\"))\n","print(\"Number of Landsat scenes: \", len(imgCol))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cawIY9cCJYpn"},"source":["Now that the image collection is client-side, we can get the arrays from each image."]},{"cell_type":"code","metadata":{"id":"H-cobA_BbwRK"},"source":["# returns a list of arrays\n","imgs_to_arrays = getArrays(imgCol)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5sg4upX_Rjdy"},"source":["## Create single dataframe of all histogram data\n","This section converts image arrays to a Pandas `DataFrame` for further analysis."]},{"cell_type":"code","metadata":{"id":"D9sJyjsi9eCF"},"source":["#@markdown Iterate through the image collection and convert the histogram bins and frequencies to a single Pandas `DataFrame`\n","length_plots = len(imgCol)\n","list_of_dfs = []\n","list_of_uids = []\n","# fig = make_subplots(rows=length_plots, cols=1)\n","for i in imgCol:\n","  uid = (i['properties']['uid']).split(\"_\")[-1]\n","  list_of_uids.append(uid)\n","  histogram = i[\"properties\"].get(\"histogram\")\n","\n","  a = pd.DataFrame(histogram, columns=[\"bin\",uid]).set_index(\"bin\")\n","  # fig.add_histogram()\n","  list_of_dfs.append(a)\n","\n","appended_dfs = pd.concat(list_of_dfs,ignore_index=False, axis=1)\n","transposed_dfs = appended_dfs.T\n","print(appended_dfs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t137gtczKEhX"},"source":["The CSV has the bins (in deg C) in the first column, the image name as the header, and the pixel counts within each bin.<p>\n","Export the `DataFrame` to a csv and copy it to your Google Drive. You can then go to your Drive and look for a file named *histograms.csv*"]},{"cell_type":"code","metadata":{"id":"70VebGE_KA--"},"source":["appended_dfs.to_csv('C1_SCA_v2_histograms.csv')\n","!cp C1_SCA_v2_histograms.csv \"drive/My Drive/NASA Landsat Temperature Product/Colab Output/C1_20211115/\"\n","print(\"file exported to Google Drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M9kRlnVPKYLV"},"source":["## View histograms using `matplotlib`"]},{"cell_type":"code","metadata":{"id":"2_AbqwwDcT9j"},"source":["#@markdown Generate histograms of lake temperature for each Landsat scene.\n","print(len(list_of_uids),\" histograms will be generated\")\n","print(\"Start:\", strftime(\"%x %X\"))\n","figure, axis = plt.subplots(len(list_of_uids),1, \n","                            figsize=(8,4*len(list_of_uids)),frameon=False, dpi=50)\n","x = appended_dfs.index\n","for row in range(0,len(list_of_uids)):\n","  uid = list_of_uids[row]\n","  y = appended_dfs[uid]\n","  axis[row].plot(x,y)\n","  axis[row].set_title(uid)\n","plt.show()\n","print(\"Finish:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1sYNsf_ndyG"},"source":["##Export to CSV"]},{"cell_type":"code","metadata":{"id":"t9STTRpLaRnD"},"source":["#@markdown Execute this cell block to export a CSV containing temperature and related image metadata\n","\n","def exportWholeLakeStats(img):\n","  img = ee.Image(img).clip(geo)\n","\n","  landsattime = img.get('system:time_start')\n","  cloudcover = img.get('CLOUD_COVER')\n","  vaporImg = ee.Image(img.get('vapor'))\n","  vaportime = vaporImg.get('system:time_start')\n","  esd = img.get(\"EARTH_SUN_DISTANCE\")\n","  elev = img.get('SUN_ELEVATION')\n","  azi = img.get('SUN_AZIMUTH')\n","  sza = img.get('sza')\n","  count = img.get('pixel_count')\n","  pctAvail = ee.Number(count).divide(totalpixels)\n","\n","  vaporMath = ee.Algorithms.If(ee.Algorithms.IsEqual(vaporImg,None),-9999,vaporImg)\n","  vaporMathg = ee.Image(vaporMath).multiply(0.1)\n","\n","  getWaterCol = vaporMathg.reduceRegion(\n","      reducer=ee.Reducer.max(),\n","      geometry=geo,\n","      bestEffort=True,\n","      scale=30\n","      )\n","  waterCol = ee.Dictionary(getWaterCol).get('pr_wtr')\n","\n","  stats = img.reduceRegion(\n","      reducer=ee.Reducer.mean().combine(\n","          reducer2=ee.Reducer.stdDev(),\n","          sharedInputs=True).combine(\n","              reducer2=ee.Reducer.minMax(),\n","              sharedInputs=True).combine(\n","                  reducer2 = ee.Reducer.median(),\n","                      sharedInputs = True).combine(\n","                          reducer2=ee.Reducer.kurtosis(),\n","                          sharedInputs = True                    \n","          ),\n","    geometry=geo,\n","    scale=30,\n","    maxPixels=5e9\n","  )\n","    \n","  \n","  more_stats = ee.Dictionary({'pixel_count':count,\n","                              'vapor_time':vaportime,\n","                              'landsat_time':landsattime,\n","                              'cloud_cover':cloudcover,\n","                              'water_column':waterCol,\n","                              'emiss':emissivity,\n","                              'elev':elev,\n","                              'azimuth':azi,\n","                              'esd':esd,\n","                              'sza':sza,\n","                              'pct_lake':pctAvail,\n","                              'l_exceltime':ee.Number(landsattime).divide(1000.0).divide(86400).add(25569),\n","                              'v_exceltime': ee.Number(vaportime).divide(1000.0).divide(86400).add(25569)\n","                              })\n","  stats2 = ee.Dictionary.combine(stats, more_stats)\n","  \n","  return ee.Feature(None,stats2)\n","\n","temp_stats = countedPixels.map(exportWholeLakeStats)\n","\n","export_task = ee.batch.Export.table.toDrive(**{\n","    'collection': temp_stats,\n","    'description': \"C1_SCA_v2_temp_stats\",\n","    \"fileFormat\": \"CSV\",\n","    'folder': \"C1_20211115\"\n","})\n","\n","print(\"Exporting 'temp_stats.csv'\")\n","export_task.start()\n","print('Polling for task (id: {}) at'.format(export_task.id))\n","\n","while export_task.active():\n","  print(strftime(\"%x %X\"), export_task.status())\n","  sleep(10)\n","\n","print(\"Finished:\", strftime(\"%x %X\"))\n","print('Export should now be visible in Drive.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1zhMxo32fmnT"},"source":["# Pair Landsat with *insitu* data\n","This next section is optional, but allows you to compare any field data you may have to the Landsat data produced here. This section uses the CSV exported above (`\"/content/drive/MyDrive/Colab Notebooks/temp_stats.csv\"`)<p>\n","In order for this to run successfully, your data must be in CSV format and have the following headers/columns:\n","\n","\n","*   `datetime`: Date and time of each temperature reading, formatted as *mm/DD/YYYY HH:MM*\n","*  `lat_dd`: latitude in decimal degrees\n","*  `lon_dd`: longitude in decimal degrees\n","*  `temp_degC`: an integer or float number representing temperature in degrees Celcius\n","*  `location`: for in-lake statistics, a column with lake zone names (string format, no special characters); can be all the same for a single output or differentiated by lake zones/ sensors\n","\n"]},{"cell_type":"markdown","metadata":{"id":"APg3jpUagGTf"},"source":["## Upload CSV of *insitu* data\n","Choose Option 1 or 2. For more ways to import data, see [here](https://colab.research.google.com/notebooks/io.ipynb)  "]},{"cell_type":"code","metadata":{"cellView":"form","id":"q99Qaurg2hHs"},"source":["#@title Please provide some information about your data\n","#@markdown What timezone is your data? [Olson Times Wikipedia Page](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones) Specifically, you need to indicate the UTC offset for your data for proper pairing, including whether or not your data timestamp observes Daylight Savings Time. Enter the text for the matching UTC offset and DST behavior from the 'TZ database name' column in the linked table. Note that the sign of the GMT offset is intentionally inverted from the UTC offset.\n","insitu_timezone = \"Etc/GMT+5\" #@param {type:\"string\"}\n","#@markdown How is your datetime formatted? Please use [strftime](https://strftime.org/) format.\n","datetime_format = \"%Y-%m-%d %H:%M:%S\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7X-Eyd1aFf7_","cellView":"form"},"source":["#@title Option 1: Link to raw CSV from Github\n","pasted_path = \"\" #@param {type:\"string\"}\n","\n","from dateutil.parser import parse\n","\n","parser = lambda date: datetime.strptime(date, datetime_format)\n","\n","is_df = pd.read_csv(pasted_path, parse_dates=[0], date_parser=parser)\n","is_df[\"datetime\"] = pd.to_datetime(is_df[\"datetime\"])\n","is_df.set_index('datetime', drop=False, inplace=True)\n","is_df.index = is_df.index.tz_localize(insitu_timezone).tz_convert(\"UTC\")\n","print(\"dataframe created\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHul1TwpD-go","cellView":"form"},"source":["#@title Option 2: Upload data from your local file system to Colab\n","#@markdown (temporary while connected to current Colab runtime session)\n","#@markdown Run this cell to upload a file\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print(\"Paste this in the box below:\\n/content/{name}\".format(name=fn))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52agyeVcKb8Z","cellView":"form"},"source":["pasted_path = \"/content/insitu_temp_data_v2021-10-20.csv\" #@param {type:\"string\"}\n","\n","is_df = pd.read_csv(pasted_path)#, parse_dates=[0], date_parser=parser)\n","#is_df[\"datetime\"] = pd.to_datetime(is_df[\"datetime\"])\n","#is_df.set_index('datetime', drop=False, inplace=True)\n","#is_df.index = is_df.index.tz_localize(insitu_timezone).tz_convert(\"UTC\")\n","print(\"dataframe created\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"CbEXkBsMgZiK"},"source":["#@title Convert local datetime to UTC time\n","#@markdown __Run this block__ to apply conversion of your specified local time to UTC time. \n","insitu_tz = pytz.timezone(insitu_timezone)\n","landsat_tz = pytz.timezone(\"UTC\")\n","\n","def convert_datetime(dt, dtformat=datetime_format):\n","  #converts string format insitu time to a datetime obj\n","  dto = datetime.strptime(dt, datetime_format)\n","  #makes it time aware\n","  dto_local = insitu_tz.localize(dto)\n","  #converts to utc\n","  dto_utc = dto_local.astimezone(landsat_tz)\n","  return dto_utc\n","\n","dtobj_series = is_df['datetime']\n","dtobj_series_conv = dtobj_series.apply(convert_datetime)\n","is_df['datetime_utc'] = dtobj_series_conv\n","\n","print(\"\\nDate/time function imported and datetime converted in dataframe\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JnJU34MEO1c-"},"source":["## Pair *insitu* data with Landsat data"]},{"cell_type":"code","metadata":{"id":"P0Gg7oRYPGqF","cellView":"form"},"source":["#@markdown Enter the window of time (in minutes) from Landsat flyover where *insitu* data should be included. For example, `timewindow = 30` will include any data within 60 minutes of Landsat flyover (+/- 30 minutes)\n","timewindow = 30 #@param {type:\"number\"\n","\n","cwd = '/content/drive/MyDrive/NASA Landsat Temperature Product/Colab Output/C1_20211115'\n","os.chdir(cwd)\n","\n","temp_filename = 'C1_SCA_v2_temp_stats'\n","\n","outfile = (\"C1_temp_landsat_paired.csv\")\n","\n","\n","print(f\"Time window: +- {timewindow} minutes\")\n","print(f\"In-situ time Zone: {insitu_timezone}\")\n","print(\"\\nLandsat input file:\\n\", os.path.join(cwd,temp_filename+\".csv\"))\n","print(\"\\nOutput file will be saved to:\\n\", os.path.join(cwd,outfile))\n","\n","min_sec = timewindow * 60"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2csZXUp0Zlo","cellView":"form"},"source":["#@markdown The following codeblock compares the datasets and generate statistics \n","#@markdown for in-lake data that matches Landsat flyovers.<br> \n","#@markdown It also uses a subfolder called 'ancillary' (and creates the folder if needed) \n","#@markdown that keeps a record of any insitu data points that are used for each Landsat scene.\n","output_dir = '/content/drive/MyDrive/NASA Landsat Temperature Product/Colab Output/C1_20211115'\n","\n","print(\"Start:\", strftime(\"%x %X\"))\n","file_name = (output_dir + '/' + temp_filename + '.csv')\n","gee_csv = pd.read_csv(file_name)\n","insitu_csv = is_df\n","\n","#make 'ancillary' folder in defined directory\n","if not os.path.exists(os.path.join(cwd, 'ancillary')):\n","    os.makedirs(os.path.join(cwd, 'ancillary'))\n","\n","\n","#filter GEE output so that it's only as recent as minimum in-situ data\n","insitumin = min(insitu_csv.datetime_utc)\n","insitumax = max(insitu_csv.datetime_utc)\n","\n","def conv_lstime(i):\n","  return pd.Timestamp(i, unit = 'ms', tz = 'utc')\n","\n","gee_csv['landsat_time_utc'] = gee_csv.landsat_time.apply(conv_lstime)\n","\n","gee_overlap = gee_csv[gee_csv.landsat_time_utc>insitumin]\n","gee_overlap_fin = gee_overlap[gee_overlap.landsat_time_utc<insitumax]\n","#reindex filtered dataset\n","gee_overlap_fin = gee_overlap_fin.reset_index(drop=True)\n","\n","gee_datelist = gee_overlap_fin[\"landsat_time_utc\"]\n","\n","# function to convert dt_delta to seconds\n","def delta_tosec(i):\n","  total_secs = i.seconds + i.days*24*60*60\n","  return total_secs\n","\n","for i in range(0,len(gee_datelist)):\n","  scene = gee_overlap_fin['system:index'][i][-20:]\n","  landsattime = gee_overlap_fin['landsat_time_utc'][i]\n","\n","  # create a df of insitu data that are observed within the user-specified cutoff \n","\n","  #calculate time delta for each obs\n","  insitu_csv['dt_delta'] = landsattime - insitu_csv['datetime_utc']\n","  insitu_csv['delta_secs'] = insitu_csv.dt_delta.apply(delta_tosec)  \n","  same_time = insitu_csv[(abs(insitu_csv.delta_secs) <= min_sec)]\n","  \n","  #if the dataframe is not empty, summarize the results\n","  if same_time.shape[0]>0:\n","    print(landsattime)\n","    gee_overlap_fin.loc[i, \"scene\"] = scene\n","    gee_overlap_fin.loc[i, \"temp_avg\"] = same_time[\"temp_degC\"].mean()\n","    gee_overlap_fin.loc[i, \"t_stdev\"] = same_time[\"temp_degC\"].std()\n","    gee_overlap_fin.loc[i, \"depth_avg\"] = same_time[\"depth_m\"].mean()\n","    gee_overlap_fin.loc[i, \"d_stdev\"] = same_time[\"depth_m\"].std()\n","    gee_overlap_fin.loc[i, \"temp_med\"] = same_time[\"temp_degC\"].median()\n","    gee_overlap_fin.loc[i, \"insitu_count\"] = same_time.shape[0]\n","\n","    site_stats = same_time.groupby(['location'])['temp_degC'].agg(['median', 'mean', 'std', 'count'])\n","\n","    sites = site_stats.axes[0]\n","    stats = site_stats.axes[1]\n","\n","    for site in sites:\n","        for stat in stats:\n","            newcol = \"{0}_{1}\".format(str(site), str(stat))\n","            gee_overlap_fin.loc[i, newcol] = site_stats[stat][site].item()\n","\n","    if same_time.shape[0] > 0:\n","        same_time.to_csv(os.path.join(cwd, 'ancillary', scene + \".csv\"))\n","\n","out_csv = gee_overlap_fin[gee_overlap_fin[\"insitu_count\"] > 0]\n","out_csv.to_csv(os.path.join(cwd, outfile))\n","(\"Finished:\", strftime(\"%x %X\"))"],"execution_count":null,"outputs":[]}]}